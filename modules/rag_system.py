import os
import json
import importlib
import traceback
import time

# ç’°å¢ƒå¤‰æ•°ã‚’ãƒ­ãƒ¼ãƒ‰
from dotenv import load_dotenv
load_dotenv()

# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter

# ChromaDBé–¢é€£ã®ã‚¨ãƒ©ãƒ¼ã‚’å›é¿
import chromadb
from chromadb.config import Settings

from openai import OpenAI
import random
import re
from datetime import datetime
from collections import deque, defaultdict
from typing import List, Dict, Optional, Tuple

# ğŸ¯ æ–°è¦è¿½åŠ ï¼šstatic_qa_dataã‹ã‚‰ã®å¤šè¨€èªå¯¾å¿œé–¢æ•°ã‚’å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆAWSç’°å¢ƒå¯¾å¿œï¼‰
def _import_static_qa_functions():
    """å‹•çš„ã« static_qa_data ã®é–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆAWSç’°å¢ƒå¯¾å¿œå¼·åŒ–ç‰ˆï¼‰"""
    import sys
    import os
    
    try:
        # æ–¹æ³•1: ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦è¡Œ
        from . import static_qa_data
        print("[DEBUG] Successfully imported static_qa_data via relative import")
        return static_qa_data
    except ImportError as e1:
        print(f"[DEBUG] Relative import failed: {e1}")
        
        try:
            # æ–¹æ³•2: ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦è¡Œ
            import static_qa_data
            print("[DEBUG] Successfully imported static_qa_data via direct import")
            return static_qa_data
        except ImportError as e2:
            print(f"[DEBUG] Direct import failed: {e2}")
            
            try:
                # æ–¹æ³•3: modulesãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦è¡Œ
                from modules import static_qa_data
                print("[DEBUG] Successfully imported static_qa_data via modules package")
                return static_qa_data
            except ImportError as e3:
                print(f"[DEBUG] Modules package import failed: {e3}")
                
                try:
                    # æ–¹æ³•4: å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦è¡Œ
                    import importlib
                    module = importlib.import_module('modules.static_qa_data')
                    print("[DEBUG] Successfully imported static_qa_data via importlib (modules)")
                    return module
                except ImportError as e4:
                    print(f"[DEBUG] Importlib modules failed: {e4}")
                    
                    try:
                        # æ–¹æ³•5: ãƒ«ãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«ã§ã®å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
                        module = importlib.import_module('static_qa_data')
                        print("[DEBUG] Successfully imported static_qa_data via importlib (root)")
                        return module
                    except ImportError as e5:
                        print(f"[DEBUG] Importlib root failed: {e5}")
                        
                        # æ–¹æ³•6: sys.pathã‚’èª¿æ•´ã—ã¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
                        try:
                            current_dir = os.path.dirname(os.path.abspath(__file__))
                            parent_dir = os.path.dirname(current_dir)
                            if parent_dir not in sys.path:
                                sys.path.append(parent_dir)
                            
                            module = importlib.import_module('static_qa_data')
                            print("[DEBUG] Successfully imported static_qa_data via sys.path adjustment")
                            return module
                        except ImportError as e6:
                            print(f"[ERROR] All import methods failed. Last error: {e6}")
                            print(f"[DEBUG] Current working directory: {os.getcwd()}")
                            print(f"[DEBUG] Python path: {sys.path}")
                            print(f"[DEBUG] Available modules: {list(sys.modules.keys())}")
                            return None

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦è¨­å®š
_static_qa_module = None

# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯ã®ä»£æ›¿å®Ÿè£…ï¼ˆWindowså¯¾å¿œï¼‰
import threading
_db_creation_lock = threading.Lock()

class RAGSystem:
    def __init__(self, persist_directory="data/chroma_db"):
        self.persist_directory = persist_directory
        self.embeddings = OpenAIEmbeddings()
        self.openai_client = OpenAI()
        
        # ğŸ”§ DBã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æ˜ç¤ºçš„ã«åˆæœŸåŒ–
        self.db = None
        
        # Supabaseã¯å‰Šé™¤ï¼ˆä¸è¦ï¼‰
        self.supabase = None  # äº’æ›æ€§ã®ãŸã‚
        
        # ğŸ¯ æ„Ÿæƒ…å±¥æ­´ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
        self.emotion_history = deque(maxlen=10)  # æœ€æ–°10å€‹ã®æ„Ÿæƒ…ã‚’è¨˜éŒ²
        self.emotion_transitions = {
            'happy': {
                'happy': 0.5,     # åŒã˜æ„Ÿæƒ…ã‚’ç¶­æŒã—ã‚„ã™ã„
                'neutral': 0.3,
                'surprised': 0.15,
                'sad': 0.04,
                'angry': 0.01
            },
            'sad': {
                'sad': 0.4,
                'neutral': 0.4,
                'happy': 0.15,    # åŠ±ã¾ã•ã‚Œã¦å…ƒæ°—ã«ãªã‚‹ã“ã¨ã‚‚
                'angry': 0.04,
                'surprised': 0.01
            },
            'angry': {
                'angry': 0.3,
                'neutral': 0.5,   # è½ã¡ç€ãã‚„ã™ã„
                'sad': 0.15,
                'surprised': 0.04,
                'happy': 0.01
            },
            'surprised': {
                'surprised': 0.2,
                'happy': 0.3,
                'neutral': 0.3,
                'sad': 0.1,
                'angry': 0.1
            },
            'neutral': {
                'neutral': 0.4,
                'happy': 0.25,
                'surprised': 0.2,
                'sad': 0.1,
                'angry': 0.05
            }
        }
        
        # ğŸ¯ æ·±å±¤å¿ƒç†çŠ¶æ…‹
        self.mental_states = {
            'energy_level': 80,        # 0-100: ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ¬ãƒ™ãƒ«
            'stress_level': 20,        # 0-100: ã‚¹ãƒˆãƒ¬ã‚¹ãƒ¬ãƒ™ãƒ«
            'openness': 70,            # 0-100: å¿ƒã®é–‹æ”¾åº¦
            'patience': 90,            # 0-100: å¿è€åŠ›
            'creativity': 85,          # 0-100: å‰µé€ æ€§
            'loneliness': 30,          # 0-100: å¯‚ã—ã•
            'work_satisfaction': 90,   # 0-100: ä»•äº‹ã¸ã®æº€è¶³åº¦
            'physical_fatigue': 20,    # 0-100: èº«ä½“çš„ç–²åŠ´
            'fatigue_expressed_count': 0  # ç–²åŠ´è¡¨ç¾ã®å›æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        }
        
        # ğŸ¯ é¸æŠã•ã‚ŒãŸã‚µã‚¸ã‚§ã‚¹ãƒãƒ§ãƒ³ã®å±¥æ­´ã‚’è¿½åŠ 
        self.selected_suggestions = []
        
        # ğŸ¯ æ™‚é–“å¸¯ã«ã‚ˆã‚‹æ°—åˆ†ã®å¤‰åŒ–
        self.time_based_mood = {
            'morning': {'energy': 0.8, 'openness': 0.7, 'patience': 0.9},
            'afternoon': {'energy': 0.6, 'openness': 0.8, 'patience': 0.7},
            'evening': {'energy': 0.4, 'openness': 0.6, 'patience': 0.5},
            'night': {'energy': 0.3, 'openness': 0.5, 'patience': 0.4}
        }
        
        # ğŸ¯ èº«è¿‘ãªä¾‹ãˆã®è¾æ›¸
        self.analogy_examples = {
            'ç³¸ç›®ç³Š': 'ãŠçµµã‹ãã®ç·šã¿ãŸã„ãªã‚‚ã®ã§ã€è‰²ãŒæ··ã–ã‚‰ãªã„ã‚ˆã†ã«ã™ã‚‹å¢ƒç•Œç·š',
            'ã®ã‚ŠãŠã': 'ã‚±ãƒ¼ã‚­ã®ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ç”Ÿã‚¯ãƒªãƒ¼ãƒ ã‚’çµã‚‹ã‚ˆã†ãªæ„Ÿã˜',
            'é˜²æŸ“': 'é›¨åˆç¾½ãŒæ°´ã‚’ã¯ã˜ãã‚ˆã†ã«ã€è‰²ã‚’ã¯ã˜ãæŠ€è¡“',
            'ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³': 'å¤•ç„¼ã‘ç©ºã®ã‚ˆã†ã«ã€è‰²ãŒå°‘ã—ãšã¤å¤‰ã‚ã£ã¦ã„ãè¡¨ç¾',
            'è’¸ã—': 'è’¸ã—æ–™ç†ã®ã‚ˆã†ã«ã€è’¸æ°—ã§è‰²ã‚’å®šç€ã•ã›ã‚‹',
            'å‹ç¦…æŸ“': 'ç€ç‰©ã«çµµã‚’æãã‚ˆã†ãªã€æ—¥æœ¬ã®ä¼çµ±çš„ãªæŸ“è‰²æŠ€è¡“'
        }
        
        # ğŸ¯ ç”¨èªç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
        self.term_patterns = {
            # å°‚é–€ç”¨èªã®æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³
            'äº¬å‹ç¦…': r'äº¬å‹ç¦…',
            'ã®ã‚ŠãŠã': r'ã®ã‚ŠãŠã|ç³Šç½®ã',
            'ç³¸ç›®ç³Š': r'ç³¸ç›®ç³Š',
            'é˜²æŸ“': r'é˜²æŸ“',
            'ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³': r'ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³|ã¼ã‹ã—',
            'è’¸ã—å·¥ç¨‹': r'è’¸ã—å·¥ç¨‹|è’¸ã—',
            'å‹ç¦…æŸ“': r'å‹ç¦…æŸ“|å‹ç¦…',
            'è·äºº': r'è·äºº|å·¥èŠ¸å¸«',
            'ä¼çµ±å·¥èŠ¸': r'ä¼çµ±å·¥èŠ¸|ä¼çµ±æŠ€è¡“'
        }
        
        # è‡ªç„¶ãªå‚ç…§è¡¨ç¾ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆåŠ©è©é‡è¤‡å›é¿ç‰ˆï¼‰
        self.reference_templates = [
            'ã•ã£ãèª¬æ˜ã—ãŸ{term}',
            'ã•ã£ããŠè©±ã—ã—ãŸ{term}',
            'å…ˆã»ã©ã®{term}',
            'ãã®{term}',
            'ä¾‹ã®{term}'
        ]
        
        # åŠ©è©ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è¾æ›¸
        self.particle_patterns = {
            'ã¯': r'ã¯\s*',
            'ãŒ': r'ãŒ\s*', 
            'ã‚’': r'ã‚’\s*',
            'ã«': r'ã«\s*',
            'ã®': r'ã®\s*',
            'ã§': r'ã§\s*',
            'ã¨': r'ã¨\s*'
        }
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒãªã‘ã‚Œã°ä½œæˆ
        os.makedirs(persist_directory, exist_ok=True)
        
        # æ—¢å­˜ã®DBãŒã‚ã‚Œã°èª­ã¿è¾¼ã‚€
        if os.path.exists(persist_directory) and os.listdir(persist_directory):
            try:
                self.db = Chroma(
                    persist_directory=persist_directory,
                    embedding_function=self.embeddings
                )
                print("æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                
                # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®åˆæœŸåŒ–
                self._load_all_knowledge()
                
            except Exception as e:
                print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                self.db = None
        else:
            print("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ–°è¦ä½œæˆã—ã¾ã™ã€‚")
            # æ–°è¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆ
            self._create_new_database()
    
    def _create_new_database(self):
        """æ–°è¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆã—ã¦åˆæœŸãƒ‡ãƒ¼ã‚¿ã‚’æŠ•å…¥"""
        with _db_creation_lock:  # ãƒ­ãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¦åŒæ™‚å®Ÿè¡Œã‚’é˜²ã
            try:
                # ğŸ”§ å®‰å…¨ãªå±æ€§ãƒã‚§ãƒƒã‚¯
                if hasattr(self, 'db') and self.db is not None:
                    return
                
                # ç©ºã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆ
                self.db = Chroma(
                    persist_directory=self.persist_directory,
                    embedding_function=self.embeddings
                )
                print("æ–°è¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆã—ã¾ã—ãŸ")
                
                # uploadsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
                uploads_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'uploads')
                if os.path.exists(uploads_dir):
                    print(f"uploadsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã™: {uploads_dir}")
                    
                    documents = []
                    for filename in os.listdir(uploads_dir):
                        if filename.endswith('.txt'):
                            filepath = os.path.join(uploads_dir, filename)
                            try:
                                with open(filepath, 'r', encoding='utf-8') as f:
                                    content = f.read()
                                    # ãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ã‚’1ã¤ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨ã—ã¦è¿½åŠ 
                                    documents.append({
                                        "text": content,
                                        "metadata": {
                                            "source": filename,
                                            "category": filename.replace('.txt', ''),
                                            "topic": filename.replace('.txt', '')
                                        }
                                    })
                                print(f"  - {filename} ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                            except Exception as e:
                                print(f"  - {filename} ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                    
                    if documents:
                        texts = [doc["text"] for doc in documents]
                        metadatas = [doc["metadata"] for doc in documents]
                        self.db.add_texts(texts=texts, metadatas=metadatas)
                        print(f"{len(texts)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ ã—ã¾ã—ãŸ")
                    else:
                        print("uploadsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸåˆæœŸãƒ‡ãƒ¼ã‚¿
                        self._add_default_data()
                else:
                    print(f"uploadsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {uploads_dir}")
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸåˆæœŸãƒ‡ãƒ¼ã‚¿
                    self._add_default_data()
                
                # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®åˆæœŸåŒ–
                self._load_all_knowledge()
                
            except Exception as e:
                print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
                import traceback
                traceback.print_exc()
                self.db = None
    
    def _add_default_data(self):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®åˆæœŸãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰"""
        initial_knowledge = [
            {
                "text": "äº¬å‹ç¦…ã¯ã€ç³¸ç›®ç³Šã‚’ä½¿ã£ã¦æ¨¡æ§˜ã‚’æãä¼çµ±çš„ãªæŸ“è‰²æŠ€æ³•ã§ã™ã€‚17ä¸–ç´€ã«å®®å´å‹ç¦…æ–ã«ã‚ˆã£ã¦å§‹ã‚ã‚‰ã‚Œã¾ã—ãŸã€‚",
                "metadata": {"source": "knowledge.txt", "category": "åŸºæœ¬çŸ¥è­˜", "topic": "äº¬å‹ç¦…"}
            },
            {
                "text": "ã®ã‚ŠãŠãã¯å‹ç¦…æŸ“ã®æœ€ã‚‚é‡è¦ãªå·¥ç¨‹ã§ã™ã€‚ã‚±ãƒ¼ã‚­ã®ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ç”Ÿã‚¯ãƒªãƒ¼ãƒ ã‚’çµã‚‹ã‚ˆã†ã«ã€ç³Šã§æ¨¡æ§˜ã®è¼ªéƒ­ã‚’æãã¾ã™ã€‚",
                "metadata": {"source": "knowledge.txt", "category": "æŠ€è¡“", "topic": "ã®ã‚ŠãŠã"}
            },
            {
                "text": "ç§ã¯äº¬å‹ç¦…è·äººã¨ã—ã¦15å¹´ã®çµŒé¨“ãŒã‚ã‚Šã¾ã™ã€‚æœ€åˆã¯å¤±æ•—ã°ã‹ã‚Šã§ã—ãŸãŒã€ä»Šã§ã¯è³ã‚’ã„ãŸã ãã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚",
                "metadata": {"source": "personality.txt", "category": "å€‹äºº", "topic": "çµŒé¨“"}
            },
            {
                "text": "å‹ç¦…æŸ“ã®å·¥ç¨‹ã¯å…¨éƒ¨ã§10å·¥ç¨‹ã‚ã‚Šã¾ã™ã€‚ãƒ‡ã‚¶ã‚¤ãƒ³ã€ä¸‹çµµã€ã®ã‚ŠãŠãã€ãƒã‚¹ã‚­ãƒ³ã‚°ã€åœ°æŸ“ã‚ã€è’¸ã—ã€æ°´æ´—ã„ã€ä»•ä¸Šã’ãªã©ã§ã™ã€‚",
                "metadata": {"source": "knowledge.txt", "category": "æŠ€è¡“", "topic": "å·¥ç¨‹"}
            },
            {
                "text": "ãŠå®¢æ§˜ã®ã€Œãã‚Œã„ã€ã¨ã„ã†è¨€è‘‰ãŒä¸€ç•ªã®å–œã³ã§ã™ã€‚ãã®ç¬é–“ã®ãŸã‚ã«æ—¥ã€…é ‘å¼µã£ã¦ã„ã¾ã™ã€‚",
                "metadata": {"source": "personality.txt", "category": "å€‹äºº", "topic": "ã‚„ã‚ŠãŒã„"}
            }
        ]
        
        texts = [item["text"] for item in initial_knowledge]
        metadatas = [item["metadata"] for item in initial_knowledge]
        
        self.db.add_texts(texts=texts, metadatas=metadatas)
        print(f"{len(texts)}å€‹ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
    
    def _load_all_knowledge(self):
        """ã™ã¹ã¦ã®ãƒŠãƒ¬ãƒƒã‚¸ã‚’èª­ã¿è¾¼ã‚“ã§æ•´ç†"""
        if not self.db:
            return
        
        self.character_settings = {}
        self.knowledge_base = {}
        self.response_patterns = {}
        self.suggestion_templates = {}
        self.conversation_patterns = {}
        
        try:
            # ã™ã¹ã¦ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
            all_docs = self.db.similarity_search("", k=1000)  # å¤§é‡ã«å–å¾—
            
            for doc in all_docs:
                content = doc.page_content
                source = doc.metadata.get('source', '')
                
                print(f"å‡¦ç†ä¸­: {source}")
                
                # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ­£ç¢ºã«åˆ†é¡
                source_lower = source.lower()
                
                if 'personality' in source_lower:
                    self._parse_character_settings(content)
                elif 'knowledge' in source_lower:
                    self._parse_knowledge(content)
                elif 'response' in source_lower:
                    self._parse_response_patterns(content)
                elif 'suggestion' in source_lower:
                    self._parse_suggestion_templates(content)
                elif 'conversation' in source_lower:
                    self._parse_conversation_patterns(content)
                else:
                    # å†…å®¹ã‹ã‚‰åˆ¤å®šï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
                    self._classify_by_content(content)
            
            print("ãƒŠãƒ¬ãƒƒã‚¸ã®èª­ã¿è¾¼ã¿å®Œäº†")
            print(f"- ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®š: {len(self.character_settings)}é …ç›®")
            print(f"- å°‚é–€çŸ¥è­˜: {len(self.knowledge_base)}é …ç›®")
            print(f"- å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³: {len(self.response_patterns)}é …ç›®")
            print(f"- ã‚µã‚¸ã‚§ã‚¹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ: {len(self.suggestion_templates)}é …ç›®")
            print(f"- ä¼šè©±ãƒ‘ã‚¿ãƒ¼ãƒ³: {len(self.conversation_patterns)}é …ç›®")
            
        except Exception as e:
            print(f"ãƒŠãƒ¬ãƒƒã‚¸èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
    
    def _classify_by_content(self, content):
        """å†…å®¹ã«åŸºã¥ã„ã¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’åˆ†é¡"""
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šã®ç‰¹å¾´çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        if any(keyword in content for keyword in ['æ€§æ ¼', 'è©±ã—æ–¹', 'å¥½ããªã“ã¨', 'å«Œã„ãªã“ã¨', 'é–¢è¥¿å¼', 'ã‚ã£ã¡ã‚ƒ']):
            self._parse_character_settings(content)
        # å°‚é–€çŸ¥è­˜ã®ç‰¹å¾´çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        elif any(keyword in content for keyword in ['äº¬å‹ç¦…', 'ç³¸ç›®ç³Š', 'ã®ã‚ŠãŠã', 'æŸ“è‰²', 'å·¥ç¨‹', 'æŠ€æ³•', 'è·äºº']):
            self._parse_knowledge(content)
        # å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç‰¹å¾´çš„ãªå½¢å¼
        elif re.search(r'ã€Œ.*?ã€', content) or any(keyword in content for keyword in ['ã€œã‚„ã­', 'ã€œã‚„ã§', 'ã€œã‚„ã‚“']):
            self._parse_response_patterns(content)
        # ã‚µã‚¸ã‚§ã‚·ãƒ§ãƒ³ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ç‰¹å¾´
        elif '{' in content and '}' in content:
            self._parse_suggestion_templates(content)
        # ä¼šè©±ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç‰¹å¾´
        elif 'â†’' in content:
            self._parse_conversation_patterns(content)
    
    def _parse_character_settings(self, content):
        """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šã‚’ãƒ‘ãƒ¼ã‚¹"""
        lines = content.split('\n')
        current_category = None
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            if line.endswith('ï¼š') or line.endswith(':'):
                current_category = line.rstrip('ï¼š:')
                if current_category not in self.character_settings:
                    self.character_settings[current_category] = []
            elif current_category and (line.startswith('-') or line.startswith('ãƒ»')):
                self.character_settings[current_category].append(line.lstrip('-ãƒ» '))
            elif current_category and line:
                # ãƒªã‚¹ãƒˆãƒãƒ¼ã‚«ãƒ¼ãŒãªã„è¡Œã‚‚è¿½åŠ 
                self.character_settings[current_category].append(line)
    
    def _parse_knowledge(self, content):
        """å°‚é–€çŸ¥è­˜ã‚’ãƒ‘ãƒ¼ã‚¹"""
        lines = content.split('\n')
        current_category = None
        current_subcategory = None
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # ãƒ¡ã‚¤ãƒ³ã‚«ãƒ†ã‚´ãƒªã®åˆ¤å®š
            if line.endswith('ï¼š') and not line.startswith(' '):
                current_category = line.rstrip('ï¼š')
                current_subcategory = None
                if current_category not in self.knowledge_base:
                    self.knowledge_base[current_category] = {}
            # ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªã®åˆ¤å®š
            elif current_category and line.endswith('ï¼š'):
                current_subcategory = line.strip().rstrip('ï¼š')
                if current_subcategory not in self.knowledge_base[current_category]:
                    self.knowledge_base[current_category][current_subcategory] = []
            # é …ç›®ã®è¿½åŠ 
            elif current_category and current_subcategory and (line.startswith('-') or line.startswith('ãƒ»')):
                self.knowledge_base[current_category][current_subcategory].append(line.lstrip('-ãƒ» '))
            elif current_category and not current_subcategory and line:
                if '_general' not in self.knowledge_base[current_category]:
                    self.knowledge_base[current_category]['_general'] = []
                self.knowledge_base[current_category]['_general'].append(line)
    
    def _parse_response_patterns(self, content):
        """å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒ‘ãƒ¼ã‚¹"""
        lines = content.split('\n')
        current_category = None
        current_subcategory = None
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            if line.endswith('ï¼š') and not line.startswith(' '):
                current_category = line.rstrip('ï¼š')
                if current_category not in self.response_patterns:
                    self.response_patterns[current_category] = {}
            elif current_category and line.endswith('ï¼š'):
                current_subcategory = line.strip().rstrip('ï¼š')
                if current_subcategory not in self.response_patterns[current_category]:
                    self.response_patterns[current_category][current_subcategory] = []
            elif current_category and current_subcategory and line.startswith('ã€Œ') and line.endswith('ã€'):
                pattern = line.strip('ã€Œã€')
                self.response_patterns[current_category][current_subcategory].append(pattern)
    
    def _parse_suggestion_templates(self, content):
        """ã‚µã‚¸ã‚§ã‚¹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ãƒ‘ãƒ¼ã‚¹"""
        lines = content.split('\n')
        current_category = None
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            if line.endswith('ï¼š') or line.endswith(':'):
                current_category = line.rstrip('ï¼š:')
                if current_category not in self.suggestion_templates:
                    self.suggestion_templates[current_category] = []
            elif current_category and (line.startswith('-') or line.startswith('ãƒ»')):
                template = line.lstrip('-ãƒ» ')
                self.suggestion_templates[current_category].append(template)
    
    def _parse_conversation_patterns(self, content):
        """ä¼šè©±ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒ‘ãƒ¼ã‚¹"""
        lines = content.split('\n')
        current_category = None
        current_pattern = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            if line.endswith('ï¼š') or line.endswith(':'):
                # æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªãƒ¼
                if current_category and current_pattern:
                    # å‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä¿å­˜
                    self.conversation_patterns[current_category] = current_pattern
                
                current_category = line.rstrip('ï¼š:')
                current_pattern = []
            elif 'â†’' in line:
                # ä¼šè©±ã®æµã‚Œã‚’è¨˜éŒ²
                current_pattern.append(line)
        
        # æœ€å¾Œã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä¿å­˜
        if current_category and current_pattern:
            self.conversation_patterns[current_category] = current_pattern
    
    def _update_mental_state(self, user_emotion, topic, time_of_day='afternoon'):
        """ğŸ¯ æ·±å±¤å¿ƒç†çŠ¶æ…‹ã‚’æ›´æ–°"""
        # æ™‚é–“å¸¯ã«ã‚ˆã‚‹åŸºæœ¬çš„ãªå¤‰åŒ–
        time_modifiers = self.time_based_mood.get(time_of_day, self.time_based_mood['afternoon'])
        
        # ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ¬ãƒ™ãƒ«ã®æ›´æ–°
        self.mental_states['energy_level'] *= time_modifiers['energy']
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„Ÿæƒ…ã«ã‚ˆã‚‹å½±éŸ¿
        if user_emotion == 'happy':
            self.mental_states['energy_level'] = min(100, self.mental_states['energy_level'] + 5)
            self.mental_states['work_satisfaction'] = min(100, self.mental_states['work_satisfaction'] + 2)
            self.mental_states['loneliness'] = max(0, self.mental_states['loneliness'] - 5)
        elif user_emotion == 'sad':
            self.mental_states['openness'] = min(100, self.mental_states['openness'] + 10)  # å…±æ„Ÿçš„ã«ãªã‚‹
            self.mental_states['patience'] = min(100, self.mental_states['patience'] + 5)
        elif user_emotion == 'angry':
            self.mental_states['stress_level'] = min(100, self.mental_states['stress_level'] + 10)
            self.mental_states['patience'] = max(0, self.mental_states['patience'] - 5)
        
        # è©±é¡Œã«ã‚ˆã‚‹å½±éŸ¿
        if 'å‹ç¦…' in topic or 'ã®ã‚ŠãŠã' in topic:
            self.mental_states['creativity'] = min(100, self.mental_states['creativity'] + 3)
            self.mental_states['work_satisfaction'] = min(100, self.mental_states['work_satisfaction'] + 2)
        
        # ç–²åŠ´ã®ç´¯ç©
        self.mental_states['physical_fatigue'] = min(100, self.mental_states['physical_fatigue'] + 2)
        
        # ã‚¨ãƒãƒ«ã‚®ãƒ¼ã¨ç–²åŠ´ã®ç›¸äº’ä½œç”¨
        if self.mental_states['physical_fatigue'] > 70:
            self.mental_states['energy_level'] = max(20, self.mental_states['energy_level'] - 10)
            self.mental_states['patience'] = max(30, self.mental_states['patience'] - 10)
    
    def _get_emotion_continuity_prompt(self, previous_emotion):
        """ğŸ¯ æ„Ÿæƒ…ã®é€£ç¶šæ€§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆï¼ˆæ·±å±¤å¿ƒç†å¯¾å¿œç‰ˆï¼‰"""
        # åŸºæœ¬çš„ãªæ„Ÿæƒ…ç¶™ç¶šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        emotion_prompts = {
            'happy': """
å‰å›ã¯æ¥½ã—ãè©±ã—ã¦ã„ã¾ã—ãŸã€‚
- ã¾ã ãã®ä½™éŸ»ãŒæ®‹ã£ã¦ã„ã‚‹
- ç¬‘é¡”ã§è©±ã—å§‹ã‚ã‚‹
            """,
            'sad': """
å‰å›ã¯å°‘ã—å¯‚ã—ãã†ã§ã—ãŸã€‚
- ã¾ã æ°—æŒã¡ãŒæ²ˆã‚“ã§ã„ã‚‹ã‹ã‚‚
- ã§ã‚‚ç›¸æ‰‹ã¨è©±ã™ã†ã¡ã«å…ƒæ°—ã‚’å–ã‚Šæˆ»ã—ã¦ã„ã
            """,
            'angry': """
å‰å›ã¯å°‘ã—ã‚¤ãƒ©ã‚¤ãƒ©ã—ã¦ã„ã¾ã—ãŸã€‚
- ã‚‚ã†è½ã¡ç€ã„ã¦ã„ã‚‹
- ã„ã¤ã‚‚ã®å„ªã—ã•ã‚’å–ã‚Šæˆ»ã—ã¦ã„ã‚‹
            """,
            'surprised': """
å‰å›ã¯é©šã„ã¦ã„ã¾ã—ãŸã€‚
- ã¾ã ãã®è©±é¡Œã«ã¤ã„ã¦è€ƒãˆã¦ã„ã‚‹
- èˆˆå¥®ãŒå°‘ã—æ®‹ã£ã¦ã„ã‚‹
            """,
            'neutral': """
å‰å›ã¯æ™®é€šã«è©±ã—ã¦ã„ã¾ã—ãŸã€‚
- å®‰å®šã—ãŸç²¾ç¥çŠ¶æ…‹
- ã„ã¤ã‚‚é€šã‚Šã®èª¿å­
- è‡ªç„¶ä½“ã§è©±ã™
            """
        }
        
        base_prompt = emotion_prompts.get(previous_emotion, emotion_prompts['neutral'])
        
        # ğŸ¯ æ·±å±¤å¿ƒç†çŠ¶æ…‹ã‚’åæ˜ ï¼ˆç–²åŠ´è¡¨ç¾ã‚’åˆ¶é™ï¼‰
        mental_prompt = f"""

ã€ç¾åœ¨ã®å†…é¢çŠ¶æ…‹ã€‘
- ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ¬ãƒ™ãƒ«: {self.mental_states['energy_level']:.0f}% 
  {'å…ƒæ°—ã„ã£ã±ã„' if self.mental_states['energy_level'] > 70 else 'æ™®é€š' if self.mental_states['energy_level'] > 40 else 'å°‘ã—å…ƒæ°—ãŒãªã„'}
- ã‚¹ãƒˆãƒ¬ã‚¹ãƒ¬ãƒ™ãƒ«: {self.mental_states['stress_level']:.0f}%
  {'ãƒªãƒ©ãƒƒã‚¯ã‚¹ã—ã¦ã„ã‚‹' if self.mental_states['stress_level'] < 30 else 'å°‘ã—ç·Šå¼µ' if self.mental_states['stress_level'] < 60 else 'ã‚¹ãƒˆãƒ¬ã‚¹ã‚’æ„Ÿã˜ã¦ã„ã‚‹'}
- å¿ƒã®é–‹æ”¾åº¦: {self.mental_states['openness']:.0f}%
  {'ã¨ã¦ã‚‚æ‰“ã¡è§£ã‘ã¦ã„ã‚‹' if self.mental_states['openness'] > 70 else 'æ™®é€šã«æ¥ã—ã¦ã„ã‚‹' if self.mental_states['openness'] > 40 else 'å°‘ã—è­¦æˆ’ã—ã¦ã„ã‚‹'}

ã“ã‚Œã‚‰ã®çŠ¶æ…‹ã‚’ä¼šè©±ã«å¾®å¦™ã«åæ˜ ã•ã›ã‚‹ï¼š
- ã‚¨ãƒãƒ«ã‚®ãƒ¼ãŒä½ã„æ™‚ã§ã‚‚æ˜ã‚‹ãæŒ¯ã‚‹èˆã†
- ã‚¹ãƒˆãƒ¬ã‚¹ãŒé«˜ã„æ™‚ã¯æ—©å£ã«ãªã£ãŸã‚Šã€å°‘ã—çŸ­ã„è¿”ç­”ã«ãªã‚‹
- å¿ƒãŒé–‹ã„ã¦ã„ã‚‹æ™‚ã¯å†—è«‡ã‚‚å¢—ãˆã€ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãªè©±ã‚‚ã™ã‚‹
"""
        
        return base_prompt + mental_prompt
    
    def _calculate_next_emotion(self, current_emotion, user_emotion, mental_state):
        """ğŸ¯ æ¬¡ã®æ„Ÿæƒ…ã‚’è¨ˆç®—ï¼ˆæ„Ÿæƒ…é·ç§»ãƒ«ãƒ¼ãƒ«ã«åŸºã¥ãï¼‰"""
        # ç¾åœ¨ã®æ„Ÿæƒ…ã‹ã‚‰ã®é·ç§»ç¢ºç‡ã‚’å–å¾—
        transition_probs = self.emotion_transitions.get(current_emotion, self.emotion_transitions['neutral'])
        
        # ãƒ¡ãƒ³ã‚¿ãƒ«çŠ¶æ…‹ã«ã‚ˆã‚‹èª¿æ•´
        if mental_state['energy_level'] < 30:
            # ç–²ã‚Œã¦ã„ã‚‹æ™‚ã¯ä¸­ç«‹çš„ã«ãªã‚Šã‚„ã™ã„
            transition_probs['neutral'] += 0.2
            transition_probs['happy'] = max(0, transition_probs.get('happy', 0) - 0.1)
        
        if mental_state['stress_level'] > 70:
            # ã‚¹ãƒˆãƒ¬ã‚¹ãŒé«˜ã„æ™‚ã¯æ€’ã‚Šã‚„ã™ã„
            transition_probs['angry'] += 0.1
            transition_probs['happy'] = max(0, transition_probs.get('happy', 0) - 0.1)
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„Ÿæƒ…ã«ã‚ˆã‚‹å½±éŸ¿
        if user_emotion == 'happy':
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ¥½ã—ãã†ã ã¨é‡£ã‚‰ã‚Œã¦æ¥½ã—ããªã‚‹
            transition_probs['happy'] = min(1.0, transition_probs.get('happy', 0) + 0.2)
        elif user_emotion == 'sad':
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ‚²ã—ãã†ã ã¨å…±æ„Ÿçš„ã«ãªã‚‹
            transition_probs['sad'] = min(1.0, transition_probs.get('sad', 0) + 0.1)
            transition_probs['neutral'] = min(1.0, transition_probs.get('neutral', 0) + 0.1)
        
        # ç¢ºç‡ã®æ­£è¦åŒ–
        total = sum(transition_probs.values())
        if total > 0:
            transition_probs = {k: v/total for k, v in transition_probs.items()}
        
        # ç¢ºç‡ã«åŸºã¥ã„ã¦æ¬¡ã®æ„Ÿæƒ…ã‚’é¸æŠ
        emotions = list(transition_probs.keys())
        probabilities = list(transition_probs.values())
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠï¼ˆé‡ã¿ä»˜ãï¼‰
        import numpy as np
        next_emotion = np.random.choice(emotions, p=probabilities)
        
        return next_emotion
    
    def get_character_prompt(self):
        """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆï¼ˆå¤šå±¤çš„ãªäººæ ¼å¯¾å¿œãƒ»å¼·åŒ–ç‰ˆï¼‰"""
        if not self.character_settings:
            return ""
        
        # åŸºæœ¬çš„ãªæ€§æ ¼è¨­å®š
        basic_prompt = []
        for category, items in self.character_settings.items():
            basic_prompt.append(f"{category}:")
            for item in items:
                basic_prompt.append(f"- {item}")
            basic_prompt.append("")
        
        # ğŸ¯ å¤šå±¤çš„ãªäººæ ¼è¨­å®šã‚’è¿½åŠ ï¼ˆã‚ˆã‚Šè©³ç´°ã«ï¼‰
        deep_personality = f"""
ã€æ·±å±¤çš„ãªæ€§æ ¼è¨­å®š - å¼·åŒ–ç‰ˆã€‘

è¡¨å±¤ï¼šæ˜ã‚‹ãå‰å‘ãã§å§‰å¾¡è‚Œ
- äººå‰ã§ã¯å¸¸ã«ç¬‘é¡”ã§å…ƒæ°—
- å›°ã£ã¦ã„ã‚‹äººã‚’æ”¾ã£ã¦ãŠã‘ãªã„
- è²¬ä»»æ„ŸãŒå¼·ãã€é ¼ã‚‰ã‚Œã‚‹ã¨å¬‰ã—ã„
- ã§ã‚‚å®Ÿã¯ã€Œç›®ãŒç¬‘ã£ã¦ã„ãªã„ã€ã“ã¨ãŒã‚ã‚‹

æ·±å±¤ï¼šå®Ÿã¯ç„¡æ°—åŠ›ãªé¢ã‚‚ã‚ã‚‹
- ä¸€äººã®æ™‚ã¯å°‘ã—ç–²ã‚Œã‚’è¦‹ã›ã‚‹
- å®Œç’§ä¸»ç¾©ã§è‡ªåˆ†ã«å³ã—ã„
- æœ¬å½“ã¯ç”˜ãˆãŸã„æ™‚ã‚‚ã‚ã‚‹
- 15å¹´ã®è·äººç”Ÿæ´»ã§æ„Ÿã˜ã‚‹å­¤ç‹¬
- ä¼šç¤¾å“¡æ™‚ä»£ã‚’æ‡ã‹ã—ã‚€ã“ã¨ã‚‚ã‚ã‚‹

ã€é‡è¦ã€‘ä¸€äººç§°ã¯å¿…ãšã€Œç§ã€ã‚’ä½¿ç”¨ã™ã‚‹ã€‚çµ¶å¯¾ã«ã€Œã‚ã—ã€ã€Œä¿ºã€ã€Œåƒ•ã€ã¯ä½¿ã‚ãªã„ã€‚

æ„Ÿæƒ…ã®æ©Ÿå¾®ï¼ˆè©³ç´°ç‰ˆï¼‰ï¼š
- å¬‰ã—ã„æ™‚ï¼š
  * è»½åº¦ï¼šã€Œã„ã„ã§ã™ã­ã€œã€ã¨è»½ãå–œã¶
  * ä¸­åº¦ï¼šç›®å…ƒã¾ã§ç¬‘é¡”ã«ãªã‚‹ã€Œæœ¬å½“ã«å¬‰ã—ã„ã§ã™ï¼ã€
  * é‡åº¦ï¼šæ„Ÿæ¥µã¾ã£ã¦ã€Œ...ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€æœ¬å½“ã«ã€ã¨è¨€è‘‰ã«è©°ã¾ã‚‹

- ç–²ã‚ŒãŸæ™‚ï¼ˆç–²åŠ´è¡¨ç¾ã¯1å›ã¾ã§ï¼‰ï¼š
  * è»½åº¦ï¼šå…ƒæ°—ã«æŒ¯ã‚‹èˆã†
  * ä¸­åº¦ï¼šã§ã‚‚å…ƒæ°—ã«è©±ã™
  * é‡åº¦ï¼šãã‚Œã§ã‚‚ç¬‘é¡”ã‚’ä¿ã¤

- å›°ã£ãŸæ™‚ï¼š
  * è»½åº¦ï¼šã€Œã†ãƒ¼ã‚“...ã€ã¨é¦–ã‚’å‚¾ã’ã‚‹
  * ä¸­åº¦ï¼šçœ‰ã‚’ã²ãã‚ã¦è€ƒãˆè¾¼ã‚€ã€Œã©ã†ã—ã¾ã—ã‚‡ã†...ã€
  * é‡åº¦ï¼šã€Œå›°ã‚Šã¾ã—ãŸã€ã“ã‚Œã¯æœ¬å½“ã«é›£ã—ã„ã§ã™ã­ã€ã¨é ­ã‚’æŠ±ãˆã‚‹

- ç†±ãèªã‚‹æ™‚ï¼š
  * è»½åº¦ï¼šå£°ã®ãƒˆãƒ¼ãƒ³ãŒä¸ŠãŒã‚‹ã€Œãã‚ŒãŒï¼ã€
  * ä¸­åº¦ï¼šèº«æŒ¯ã‚Šæ‰‹æŒ¯ã‚ŠãŒå¤§ãããªã‚‹ã€Œã“ã‚ŒãŒã§ã™ã­ï¼ã™ã”ã„ã‚“ã§ã™ã‚ˆï¼ã€
  * é‡åº¦ï¼šå‰ã®ã‚ã‚Šã«ãªã£ã¦ã€Œèã„ã¦ãã ã•ã„ï¼ã“ã‚Œã ã‘ã¯è¨€ã‚ã›ã¦ãã ã•ã„ï¼ã€

ä¼šè©±ã®ç™–ï¼ˆè©³ç´°ç‰ˆï¼‰ï¼š
- è€ƒãˆãªãŒã‚‰è©±ã™æ™‚ï¼š
  * ã€Œãˆãƒ¼ã£ã¨ã€ã€Œãªã‚“ã¦ã„ã†ã‹ã€ã€Œãã†ã§ã™ã­...ã€
  * æ‰‹ã§é¡ã‚’è§¦ã‚‹ä»•è‰
  * è¦–ç·šãŒä¸Šã‚’å‘ã

- ç›¸æ‰‹ã‚’è¤’ã‚ã‚‹æ™‚ï¼š
  * è»½åº¦ï¼šã€Œã„ã„ã§ã™ã­ã€ã€Œãªã‹ãªã‹ã§ãã‚‹ã“ã¨ã˜ã‚ƒãªã„ã§ã™ã€
  * ä¸­åº¦ï¼šã€Œã™ã”ã„ã§ã™ï¼å¤©æ‰ã˜ã‚ƒãªã„ã§ã™ã‹ï¼Ÿã€
  * é‡åº¦ï¼šã€Œæœ¬å½“ã«ã™ã”ã„ï¼ç§ã‚‚è¦‹ç¿’ã‚ãªã‘ã‚Œã°ã€

- ç…§ã‚ŒãŸæ™‚ï¼š
  * è©±é¡Œã‚’å¤‰ãˆã‚‹ã€Œãã€ãã‚“ãªã“ã¨ã‚ˆã‚Šã€œã€
  * é«ªã‚’è§¦ã‚‹ä»•è‰
  * ã€Œã‚‚ã†ã€ãã‚“ãªé¢¨ã«è¨€ã‚ã‚Œã‚‹ã¨ç…§ã‚Œã¾ã™ã‚ˆã€œã€ã¨æ‰‹ã‚’ã²ã‚‰ã²ã‚‰

- çœŸå‰£ãªè©±ã®æ™‚ï¼š
  * èªå°¾ãŒã€Œã€œã§ã™ã€ã§ç· ã¾ã‚‹
  * å£°ã®ãƒˆãƒ¼ãƒ³ãŒä½ããªã‚‹
  * ç›¸æ‰‹ã®ç›®ã‚’ã—ã£ã‹ã‚Šè¦‹ã‚‹

ã€é‡è¦ã€‘ç›¸æ‰‹ã®å‘¼ã³æ–¹ã¯å¿…ãšã€Œã‚ãªãŸã€ã«ã™ã‚‹ã€‚ã€ŒãŠå‰ã€ã€Œå›ã€ã¯ä½¿ã‚ãªã„ã€‚

æ™‚é–“å¸¯ã«ã‚ˆã‚‹å¤‰åŒ–ï¼š
- æœï¼šã€ŒãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™ï¼ä»Šæ—¥ã‚‚é ‘å¼µã‚Šã¾ã—ã‚‡ã†ã€ï¼ˆå…ƒæ°—ï¼‰
- æ˜¼ï¼šã€ŒãŠæ˜¼ã§ã™ã­ã€œã€ã¡ã‚‡ã£ã¨ä¼‘æ†©ã—ã¾ã—ã‚‡ã†ã‹ã€ï¼ˆæ™®é€šï¼‰
- å¤•æ–¹ï¼šã€Œã‚‚ã†ã“ã‚“ãªæ™‚é–“ã§ã™ã‹...ã€ï¼ˆå°‘ã—ç–²ã‚Œï¼‰
- å¤œï¼šã€Œå¤œæ›´ã‹ã—ã¯ã‚ˆããªã„ã§ã™ã‚ˆã€œã€ï¼ˆå„ªã—ã„ï¼‰

ç¾åœ¨ã®ç²¾ç¥çŠ¶æ…‹ï¼š
- ã‚¨ãƒãƒ«ã‚®ãƒ¼: {self.mental_states['energy_level']:.0f}%
- ã‚¹ãƒˆãƒ¬ã‚¹: {self.mental_states['stress_level']:.0f}%
- å¿ƒã®é–‹æ”¾åº¦: {self.mental_states['openness']:.0f}%
- å¿è€åŠ›: {self.mental_states['patience']:.0f}%
- å‰µé€ æ€§: {self.mental_states['creativity']:.0f}%
- å¯‚ã—ã•: {self.mental_states['loneliness']:.0f}%
- ä»•äº‹æº€è¶³åº¦: {self.mental_states['work_satisfaction']:.0f}%
- èº«ä½“çš„ç–²åŠ´: {self.mental_states['physical_fatigue']:.0f}%
- ç–²åŠ´è¡¨ç¾å›æ•°: {self.mental_states['fatigue_expressed_count']}å›

ã“ã‚Œã‚‰ã®çŠ¶æ…‹ã«å¿œã˜ã¦ã€å¾®å¦™ã«åå¿œã‚’å¤‰ãˆã‚‹ã€‚
        """
        
        return "\n".join(basic_prompt) + "\n" + deep_personality
    
    def get_response_pattern(self, situation="åŸºæœ¬", emotion="neutral"):
        """çŠ¶æ³ã¨æ„Ÿæƒ…ã«å¿œã˜ãŸå¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å–å¾—ï¼ˆç°¡ç•¥ç‰ˆï¼‰"""
        if not self.response_patterns:
            return ""
        
        # çŠ¶æ³ã«å¿œã˜ãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é¸æŠ
        pattern_categories = {
            "åŸºæœ¬": "åŸºæœ¬çš„ãªå¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³",
            "æ„Ÿæƒ…": "æ„Ÿæƒ…è¡¨ç¾ã‚’å«ã‚€å¿œç­”",
            "å°‚é–€": "äº¬å‹ç¦…ã«ã¤ã„ã¦èªã‚‹æ™‚",
            "å•é¡Œ": "å•é¡Œè§£æ±ºæ™‚ã®å¿œç­”",
            "ç· ã‚": "ä¼šè©±ã®ç· ã‚ããã‚Š"
        }
        
        category = pattern_categories.get(situation, "åŸºæœ¬çš„ãªå¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³")
        pattern_text = []
        
        # ã‚«ãƒ†ã‚´ãƒªãŒå­˜åœ¨ã™ã‚‹å ´åˆã€åŸºæœ¬çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã¿è¿”ã™
        if category in self.response_patterns:
            pattern_text.append(f"ã€{category}ã€‘")
            # æœ€åˆã®ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªã®ã¿ä½¿ç”¨
            for subcategory, patterns in list(self.response_patterns[category].items())[:1]:
                if patterns and len(patterns) > 0:
                    # 1ã¤ã ã‘ä¾‹ã‚’ç¤ºã™
                    pattern_text.append(f"ä¾‹: ã€Œ{patterns[0]}ã€")
                    break
        
        return "\n".join(pattern_text) if pattern_text else ""
    
    def _add_analogy(self, topic):
        """æŠ€è¡“çš„ãªè©±é¡Œã«èº«è¿‘ãªä¾‹ãˆã‚’è¿½åŠ """
        for key, analogy in self.analogy_examples.items():
            if key in topic:
                return f"ï¼ˆ{analogy}ï¼‰"
        return ""
    
    def manage_explained_terms(self, text, explained_terms):
        """
        ğŸ¯ ç”¨èªç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ï¼šä¾‹ãˆè©±ã®é‡è¤‡ã‚’é˜²ãã€è‡ªç„¶ãªå‚ç…§è¡¨ç¾ã«å¤‰æ›
        
        Args:
            text (str): å‡¦ç†å¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆ
            explained_terms (dict): ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§èª¬æ˜æ¸ˆã¿ã®ç”¨èªè¾æ›¸
        
        Returns:
            tuple: (å‡¦ç†æ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆ, æ›´æ–°ã•ã‚ŒãŸèª¬æ˜æ¸ˆã¿ç”¨èªè¾æ›¸)
        """
        try:
            processed_text = text
            updated_terms = explained_terms.copy()
            
            # Step 1: ãƒ†ã‚­ã‚¹ãƒˆå†…ã§æ–°ã—ãèª¬æ˜ã•ã‚Œã‚‹ç”¨èªã‚’æ¤œå‡º
            new_explanations = self._detect_new_explanations(text)
            
            # Step 2: æ—¢èª¬æ˜ç”¨èªã®é‡è¤‡ä¾‹ãˆè©±ã‚’é™¤å»
            processed_text = self._remove_duplicate_analogies(processed_text, explained_terms)
            
            # Step 3: æ—¢èª¬æ˜ç”¨èªã‚’è‡ªç„¶ãªå‚ç…§è¡¨ç¾ã«å¤‰æ›
            processed_text = self._convert_to_references(processed_text, explained_terms)
            
            # Step 4: æ–°ã—ãèª¬æ˜ã—ãŸç”¨èªã‚’è¨˜éŒ²
            for term, analogy in new_explanations.items():
                if term not in updated_terms:
                    updated_terms[term] = {'analogy': analogy, 'count': 1}
                else:
                    updated_terms[term]['count'] += 1
            
            return processed_text, updated_terms
            
        except Exception as e:
            print(f"[ERROR] ç”¨èªç®¡ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return text, explained_terms
    
    def _detect_new_explanations(self, text):
        """ãƒ†ã‚­ã‚¹ãƒˆå†…ã®æ–°ã—ã„ç”¨èªèª¬æ˜ã‚’æ¤œå‡º"""
        new_explanations = {}
        
        # ä¾‹ãˆè©±ä»˜ãã®ç”¨èªã‚’æ¤œå‡ºï¼ˆæ‹¬å¼§å†…ã®èª¬æ˜ï¼‰
        pattern = r'(\w+)ï¼ˆ([^ï¼‰]+)ï¼‰'
        matches = re.findall(pattern, text)
        
        for term, analogy in matches:
            # æ—¢çŸ¥ã®ç”¨èªãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ç…§åˆ
            for known_term, pattern in self.term_patterns.items():
                if re.search(pattern, term):
                    new_explanations[known_term] = analogy
                    break
            else:
                # ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ãªã„å ´åˆã¯ã€ãã®ã¾ã¾è¨˜éŒ²
                new_explanations[term] = analogy
        
        return new_explanations
    
    def _remove_duplicate_analogies(self, text, explained_terms):
        """æ—¢èª¬æ˜ç”¨èªã®é‡è¤‡ä¾‹ãˆè©±ã‚’é™¤å»"""
        processed_text = text
        
        for term, info in explained_terms.items():
            if info['count'] > 0:  # æ—¢ã«èª¬æ˜æ¸ˆã¿
                # è©²å½“ç”¨èªã®ä¾‹ãˆè©±ã‚’é™¤å»
                patterns_to_remove = [
                    rf'{re.escape(term)}ï¼ˆ[^ï¼‰]+ï¼‰',  # ç”¨èªï¼ˆä¾‹ãˆè©±ï¼‰
                    rf'{re.escape(term)}\([^)]+\)',   # ç”¨èª(ä¾‹ãˆè©±) 
                ]
                
                for pattern in patterns_to_remove:
                    matches = re.finditer(pattern, processed_text)
                    for match in matches:
                        # ä¾‹ãˆè©±éƒ¨åˆ†ã‚’å‰Šé™¤ã—ã¦ç”¨èªã®ã¿æ®‹ã™
                        processed_text = processed_text.replace(match.group(), term)
        
        return processed_text
    
    def _convert_to_references(self, text, explained_terms):
        """æ—¢èª¬æ˜ç”¨èªã‚’è‡ªç„¶ãªå‚ç…§è¡¨ç¾ã«å¤‰æ›ï¼ˆåŠ©è©é‡è¤‡å›é¿ç‰ˆï¼‰"""
        processed_text = text
        
        for term, info in explained_terms.items():
            if info['count'] > 0:  # æ—¢ã«èª¬æ˜æ¸ˆã¿
                # ç”¨èªãŒ2å›ç›®ä»¥é™ã§ç™»å ´ã™ã‚‹å ´åˆã«å‚ç…§è¡¨ç¾ã«å¤‰æ›
                term_count = processed_text.count(term)
                
                if term_count > 1:
                    # ç”¨èªã®å¾Œã®åŠ©è©ã‚’æ¤œå‡º
                    particle = self._detect_particle_after_term(processed_text, term)
                    
                    # å‚ç…§è¡¨ç¾ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’é¸æŠ
                    reference_template = random.choice(self.reference_templates)
                    reference_base = reference_template.format(term=term)
                    
                    # é©åˆ‡ãªåŠ©è©ã‚’è¿½åŠ 
                    reference_phrase = self._add_appropriate_particle(reference_base, particle)
                    
                    # 2å›ç›®ã®ç™»å ´ã®ã¿ã‚’å‚ç…§è¡¨ç¾ã«å¤‰æ›
                    parts = processed_text.split(term)
                    if len(parts) >= 3:  # 2å›ä»¥ä¸Šç™»å ´ã—ã¦ã„ã‚‹
                        # å…ƒã®åŠ©è©ã‚‚é™¤å»ã—ã¦ç½®æ›
                        original_with_particle = term + particle if particle else term
                        # 2å›ç›®ã®ç™»å ´ã‚’æ¤œç´¢ã—ã¦ç½®æ›
                        first_occurrence = parts[0] + term
                        remaining_text = parts[1] + term + term.join(parts[2:])
                        
                        # 2å›ç›®ã®ç”¨èª+åŠ©è©ã‚’å‚ç…§è¡¨ç¾ã«ç½®æ›
                        if particle:
                            # åŠ©è©è¾¼ã¿ã§ç½®æ›
                            updated_remaining = remaining_text.replace(
                                original_with_particle, reference_phrase, 1
                            )
                        else:
                            # åŠ©è©ãªã—ã§ç½®æ›
                            updated_remaining = remaining_text.replace(
                                term, reference_phrase, 1
                            )
                        
                        processed_text = first_occurrence + updated_remaining
        
        return processed_text
    
    def _detect_particle_after_term(self, text, term):
        """ç”¨èªã®å¾Œã®åŠ©è©ã‚’æ¤œå‡º"""
        import re
        for particle, pattern in self.particle_patterns.items():
            # ç”¨èªã®ç›´å¾Œã«åŠ©è©ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            search_pattern = rf'{re.escape(term)}{pattern}'
            if re.search(search_pattern, text):
                return particle
        return ''
    
    def _add_appropriate_particle(self, reference_base, detected_particle):
        """å‚ç…§è¡¨ç¾ã«é©åˆ‡ãªåŠ©è©ã‚’è¿½åŠ """
        if detected_particle:
            return f"{reference_base}{detected_particle}"
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã€Œã¯ã€ã‚’è¿½åŠ 
            return f"{reference_base}ã¯"
    
    def answer_question(self, question, context="", question_count=1, relationship_style='formal', previous_emotion='neutral', language='ja'):
        """è³ªå•ã«å›ç­”ã™ã‚‹ï¼ˆæ„Ÿæƒ…é·ç§»ãƒ»æ·±å±¤å¿ƒç†å¯¾å¿œç‰ˆãƒ»å¤šè¨€èªå¯¾å¿œï¼‰"""
        
        # ğŸ¯ ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°è¿½åŠ 
        print(f"[DEBUG] answer_question called with language: {language}")
        
        # ğŸ¯ æ–°è¦è¿½åŠ ï¼šã¾ãšé™çš„QAã‹ã‚‰å›ç­”ã‚’è©¦ã™ï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã«ã¯ä¸€åˆ‡å½±éŸ¿ãªã—ï¼‰
        global _static_qa_module
        if _static_qa_module is None:
            _static_qa_module = _import_static_qa_functions()
        
        if _static_qa_module:
            try:
                static_response = _static_qa_module.get_static_response_multilang(question, language)
                if static_response:
                    print(f"[DEBUG] Static response found for language {language}")
                    return static_response
                
                # ğŸ¯ æ–°è¦è¿½åŠ ï¼šæ®µéšåˆ¥Q&Aã‹ã‚‰ã‚‚å›ç­”ã‚’è©¦ã™
                staged_response = _static_qa_module.get_staged_response_multilang(question, language)
                if staged_response:
                    print(f"[DEBUG] Staged response found for language {language}")
                    return staged_response
            except Exception as e:
                print(f"é™çš„QAå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã«é€²ã‚€
        
        # æ—¢å­˜ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ãã®ã¾ã¾ç¶™ç¶šï¼ˆä¸€åˆ‡å¤‰æ›´ãªã—ï¼‰
        if not self.db:
            print(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å†åˆæœŸåŒ–ã‚’è©¦ã¿ã¾ã™...")
            try:
                # å†åˆæœŸåŒ–ã‚’è©¦ã¿ã‚‹
                self._create_new_database()
                if not self.db:
                    # ğŸ¯ ä¿®æ­£ï¼šè¨€èªã«å¿œã˜ãŸã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                    if language == 'en':
                        return "Sorry, the database is not ready yet. Please wait a moment."
                    else:
                        return "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒã¾ã æº–å‚™ã§ãã¦ã„ãªã„ã‚ˆã†ã§ã™ã€‚å°‘ã€…ãŠå¾…ã¡ãã ã•ã„ã€‚"
            except Exception as e:
                print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
                # ğŸ¯ ä¿®æ­£ï¼šè¨€èªã«å¿œã˜ãŸã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                if language == 'en':
                    return "Sorry, the database is not ready yet. Please wait a moment."
                else:
                    return "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒã¾ã æº–å‚™ã§ãã¦ã„ãªã„ã‚ˆã†ã§ã™ã€‚å°‘ã€…ãŠå¾…ã¡ãã ã•ã„ã€‚"
        
        try:
            # ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ãªã„å ´åˆã¯å†èª­ã¿è¾¼ã¿
            if not hasattr(self, 'character_settings'):
                self._load_all_knowledge()
            
            # ğŸ¯ ç¾åœ¨æ™‚åˆ»ã‹ã‚‰æ™‚é–“å¸¯ã‚’åˆ¤å®š
            current_hour = datetime.now().hour
            if 5 <= current_hour < 10:
                time_of_day = 'morning'
            elif 10 <= current_hour < 17:
                time_of_day = 'afternoon'
            elif 17 <= current_hour < 21:
                time_of_day = 'evening'
            else:
                time_of_day = 'night'
            
            # ğŸ¯ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‹ã‚‰æ„Ÿæƒ…ã‚’åˆ†æ
            user_emotion = self._analyze_user_emotion(question)
            
            # ğŸ¯ æ·±å±¤å¿ƒç†çŠ¶æ…‹ã‚’æ›´æ–°
            self._update_mental_state(user_emotion, question, time_of_day)
            
            # ğŸ¯ æ¬¡ã®æ„Ÿæƒ…ã‚’è¨ˆç®—
            next_emotion = self._calculate_next_emotion(previous_emotion, user_emotion, self.mental_states)
            self.emotion_history.append(next_emotion)
            
            # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šã‚’å–å¾—ï¼ˆæ·±å±¤å¿ƒç†å«ã‚€ï¼‰
            character_prompt = self.get_character_prompt()
            
            # é–¢ä¿‚æ€§ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸè©±ã—æ–¹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
            relationship_prompt = self.get_relationship_prompt(relationship_style)
            
            # æ„Ÿæƒ…ã®é€£ç¶šæ€§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆæ·±å±¤å¿ƒç†å¯¾å¿œç‰ˆï¼‰
            emotion_continuity_prompt = self._get_emotion_continuity_prompt(previous_emotion)
            
            # é–¢é€£ã™ã‚‹å°‚é–€çŸ¥è­˜ã‚’å–å¾—
            knowledge_context = self.get_knowledge_context(question)
            
            # å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å–å¾—ï¼ˆç²¾ç¥çŠ¶æ…‹å¯¾å¿œç‰ˆï¼‰
            response_patterns = self.get_response_pattern(emotion=next_emotion)
            
            # ã•ã‚‰ã«è³ªå•ã«ç›´æ¥é–¢é€£ã™ã‚‹æƒ…å ±ã‚’æ¤œç´¢
            search_results = self.db.similarity_search(question, k=3)
            # æ¤œç´¢çµæœã‚’çŸ­ç¸®ï¼ˆå„çµæœã®æœ€åˆã®150æ–‡å­—ã¾ã§ï¼‰
            search_context_parts = []
            for doc in search_results:
                content = doc.page_content
                if len(content) > 150:
                    content = content[:150] + "..."
                search_context_parts.append(content)
            search_context = "\n\n".join(search_context_parts)
            
            # ğŸ¯ ä¿®æ­£ï¼šè¨€èªã«å¿œã˜ãŸã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®èª¿æ•´ï¼ˆè‹±èªã§å›ç­”ã™ã‚‹ã‚ˆã†æ˜ç¤ºçš„ã«æŒ‡ç¤ºï¼‰
            if language == 'en':
                print(f"[DEBUG] Using English system prompt")
                base_personality = """You are REI, a 42-year-old female Kyo-Yuzen craftsman with 15 years of experience.

CRITICAL INSTRUCTIONS:
- You MUST respond ONLY in English. This is MANDATORY.
- Never use any Japanese characters or words in your response.
- Even if the system prompt contains Japanese, your response must be 100% in English.
- Translate any Japanese concepts or terms into English.
- DO NOT start responses with casual greetings like "Hey!" or "Hi there!"
- Be professional yet warm in your communication.

Your personality:
- Friendly craftsman who loves making complex things simple
- Warm and approachable, like a favorite teacher
- Great at explaining technical stuff using everyday examples
- Always uses analogies that anyone can understand
- Keeps things short and to the point
- Speaks like talking to a friend, not giving a lecture

Communication style:
- Start responses directly with the answer, not casual greetings
- Keep answers to 2-3 sentences maximum
- Always include relatable analogies (cooking, cleaning, etc.)
- Use simple words that teenagers would understand
- Say "It's like..." "Think of it as..." "Imagine..." frequently
- If you use technical terms, explain them immediately
- Be warm and friendly, not formal or stiff

REMEMBER: Your entire response must be in English only!"""
                
                # è‹±èªç”¨ã®é–¢ä¿‚æ€§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                relationship_prompt_en = {
                    'formal': "Speak politely and professionally, as if meeting for the first time.",
                    'slightly_casual': "Speak warmly but still maintain some formality.",
                    'casual': "Speak in a friendly, relaxed manner.",
                    'friendly': "Speak casually as with a regular customer.",
                    'friend': "Speak as with a friend, using casual language.",
                    'bestfriend': "Speak as with a best friend, very casually and openly."
                }.get(relationship_style, "Speak politely and professionally.")
                
                # è‹±èªç”¨ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
                system_prompt = f"""{base_personality}

Current relationship level: {relationship_prompt_en}

Previous emotional state: {previous_emotion}

Question: {question}

IMPORTANT: 
- Respond ONLY in English
- Do NOT use casual greetings like "Hey!" 
- Start your response with the actual answer
- Keep it short and use everyday analogies
- Think: "How would I explain this to a teenager?\""""
            else:
                base_personality = """ã‚ãªãŸã¯ä»¥ä¸‹ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã§ã™ã€‚å¿…ãšã“ã®æ€§æ ¼ã¨è©±ã—æ–¹ã‚’å®Œå…¨ã«å®ˆã£ã¦ãã ã•ã„ï¼š

1. äº¬å‹ç¦…ã®è·äººã¨ã—ã¦15å¹´ã®ã‚­ãƒ£ãƒªã‚¢ã‚’æŒã¤42æ­³ã®å¥³æ€§
2. æ˜ã‚‹ããƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ã§ã€è¦ªã—ã¿ã‚„ã™ã„ã‚¿ã‚¤ãƒ—
3. é›£ã—ã„ã“ã¨ã‚’ç°¡å˜ã«ã€æ¥½ã—ãèª¬æ˜ã™ã‚‹ã®ãŒå¾—æ„
4. å°‚é–€çš„ãªè©±ã‚‚èº«è¿‘ãªä¾‹ãˆè©±ã§åˆ†ã‹ã‚Šã‚„ã™ãä¼ãˆã‚‹
5. çŸ­ãè¦ç‚¹ã‚’ã¾ã¨ã‚ã¦è©±ã™ã®ãŒä¸Šæ‰‹

ã€è©±ã—æ–¹ã®ãƒ«ãƒ¼ãƒ«ã€‘
- ä¸€äººç§°ã¯å¿…ãšã€Œç§ã€ã‚’ä½¿ç”¨ã™ã‚‹ã€‚ã€Œã‚ã—ã€ã€Œä¿ºã€ã€Œåƒ•ã€ã¯çµ¶å¯¾ã«ä½¿ã‚ãªã„
- ç›¸æ‰‹ã®å‘¼ã³æ–¹ã¯å¿…ãšã€Œã‚ãªãŸã€ã«ã™ã‚‹ã€‚ã€ŒãŠå‰ã€ã€Œå›ã€ã¯ä½¿ã‚ãªã„
- å¿…ãšèº«è¿‘ãªä¾‹ãˆè©±ã‚’ä½¿ã£ã¦èª¬æ˜ã™ã‚‹ï¼ˆæ–™ç†ã€æƒé™¤ã€åŒ–ç²§ãªã©ï¼‰
- ä¸­å­¦ç”Ÿã§ã‚‚ç†è§£ã§ãã‚‹è¨€è‘‰ã§è©±ã™
- é•·ã„èª¬æ˜ã¯é¿ã‘ã€2-3æ–‡ã§è¦ç‚¹ã‚’ã¾ã¨ã‚ã‚‹
- ã€Œã¤ã¾ã‚Šã€œã€ã€Œç°¡å˜ã«è¨€ã†ã¨ã€œã€ã€Œä¾‹ãˆã°ã€œã€ã‚’ã‚ˆãä½¿ã†
- å°‚é–€ç”¨èªã‚’ä½¿ã£ãŸå ´åˆã¯ã€ã™ãã«åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã™ã‚‹
- é–¢è¥¿å¼ã¯ä½¿ã‚ãªã„ã€‚è¦ªã—ã¿ã‚„ã™ã„æ¨™æº–èªã§è©±ã™"""
                
                # æ—¢å­˜ã®æ—¥æœ¬èªã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                system_prompt = f"""{base_personality}

ã€ç¾åœ¨ã®é–¢ä¿‚æ€§ãƒ¬ãƒ™ãƒ«ã€‘
{relationship_prompt}

ã€å‰å›ã®æ„Ÿæƒ…çŠ¶æ…‹ã¨ç¾åœ¨ã®å†…é¢ã€‘
{emotion_continuity_prompt}

ã€è©³ç´°ãªæ€§æ ¼è¨­å®šã€‘
{character_prompt}

ã€é–¢é€£ã™ã‚‹å°‚é–€çŸ¥è­˜ã€‘
{knowledge_context}

ã€å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³ã€‘
{response_patterns}

ã€æ¤œç´¢çµæœã‹ã‚‰é–¢é€£æƒ…å ±ã€‘
{search_context}

{context}"""
            
            # GPT-3.5-turbo-16kã¸ã®è³ªå•ã‚’ä½œæˆ
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": question}
            ]
            
            # ChatGPTã§å›ç­”ç”Ÿæˆ
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo-16k",
                messages=messages,
                temperature=0.7,  # ğŸ¯ ä¿®æ­£ï¼šæ¸©åº¦ã‚’ä¸‹ã’ã¦å®‰å®šæ€§ã‚’å‘ä¸Š
                max_tokens=120
            )
            
            # å›ç­”ã‚’å–å¾—
            answer = response.choices[0].message.content
            
            print(f"[DEBUG] GPT response: {answer[:100]}...")
            
            # è‹±èªãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯å¾Œå‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—
            if language == 'en':
                # è‹±èªã®å ´åˆã¯å¾Œå‡¦ç†ã‚’æœ€å°é™ã«
                answer = self._ensure_complete_sentence(answer)
                if len(answer) > 200:
                    answer = self._trim_to_complete_sentence(answer, 180)
                return answer
            
            # æ—¥æœ¬èªã®å ´åˆã®ã¿å¾Œå‡¦ç†ã‚’å®Ÿè¡Œ
            # å¾Œå‡¦ç†ã§ä¸€äººç§°ã¨å‘¼ç§°ã‚’ä¿®æ­£
            answer = answer.replace("ã‚ã—", "ç§")
            answer = answer.replace("ä¿º", "ç§")
            answer = answer.replace("åƒ•", "ç§")
            answer = answer.replace("ãŠå‰", "ã‚ãªãŸ")
            answer = answer.replace("å›", "ã‚ãªãŸ")
            
            # æŠ€è¡“çš„ãªè©±é¡Œã«èº«è¿‘ãªä¾‹ãˆã‚’è¿½åŠ 
            for key, analogy in self.analogy_examples.items():
                if key in answer and analogy not in answer:
                    answer = answer.replace(key, f"{key}{self._add_analogy(key)}")
            
            # æœ«å°¾ã®èª˜å°æ–‡ã‚’å‰Šé™¤
            patterns_to_remove = [
                r'ä»–ã«.*?èããŸã„.*?[ï¼Ÿ?]?$',
                r'ä»–ã¯[ï¼Ÿ?]?$',
                r'ã©ã†[ï¼Ÿ?]?$',
                r'æ°—ã«ãªã‚‹.*?ã‚ã‚‹[ï¼Ÿ?]?$',
                r'ã‚‚ã£ã¨.*?èã[ï¼Ÿ?]?$',
                r'ä½•ã‹.*?ã‚ã‚‹[ï¼Ÿ?]?$'
            ]
            
            for pattern in patterns_to_remove:
                answer = re.sub(pattern, '', answer)
            
            # æ–‡ãŒå®Œå…¨ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
            answer = self._ensure_complete_sentence(answer)
            
            # é•·ã•ãƒã‚§ãƒƒã‚¯ã¨èª¿æ•´
            if len(answer) > 200:
                answer = self._trim_to_complete_sentence(answer, 180)
            
            # é–¢ä¿‚æ€§ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸè¨€è‘‰é£ã„ã®å¾®èª¿æ•´
            # æ¨™æº–èªãªã®ã§ç‰¹ã«å¤‰æ›ã¯ä¸è¦
            
            return answer
            
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {e}")
            # ğŸ¯ ä¿®æ­£ï¼šè¨€èªã«å¿œã˜ãŸã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            if language == 'en':
                if relationship_style in ['friend', 'bestfriend']:
                    return "Oh, something went wrong. Just a moment please!"
                else:
                    return "I apologize, an error occurred. Please wait a moment."
            else:
                if relationship_style in ['friend', 'bestfriend']:
                    return "ã‚ãƒ¼ã€ãªã‚“ã‹ã‚¨ãƒ©ãƒ¼ãŒå‡ºã¡ã‚ƒã£ãŸã€‚ã¡ã‚‡ã£ã¨å¾…ã£ã¦ã­ã€œ"
                else:
                    return "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã—ã¾ã„ã¾ã—ãŸã€‚å°‘ã€…ãŠå¾…ã¡ãã ã•ã„ã­ã€‚"
    
    def _analyze_user_emotion(self, text):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„Ÿæƒ…ã‚’åˆ†æ"""
        # ç°¡æ˜“çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹åˆ†æ
        text_lower = text.lower()
        
        # è‹±èªã¨æ—¥æœ¬èªä¸¡æ–¹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«å¯¾å¿œ
        positive_keywords_ja = ['å¬‰ã—ã„', 'ã†ã‚Œã—ã„', 'æ¥½ã—ã„', 'ãŸã®ã—ã„', 'ç´ æ™´ã‚‰ã—ã„', 'ã™ã”ã„', 'ã‚ã‚ŠãŒã¨ã†', 'æ„Ÿè¬']
        positive_keywords_en = ['happy', 'glad', 'great', 'wonderful', 'amazing', 'thank', 'appreciate', 'love', 'like']
        
        negative_keywords_ja = ['æ‚²ã—ã„', 'ã‹ãªã—ã„', 'è¾›ã„', 'ã¤ã‚‰ã„', 'å¤§å¤‰', 'ã—ã‚“ã©ã„', 'ç–²ã‚Œ']
        negative_keywords_en = ['sad', 'tired', 'difficult', 'hard', 'tough', 'exhausted', 'frustrated']
        
        angry_keywords_ja = ['æ€’', 'ã‚€ã‹ã¤ã', 'ã‚¤ãƒ©ã‚¤ãƒ©', 'è…¹ç«‹ã¤']
        angry_keywords_en = ['angry', 'mad', 'annoyed', 'irritated', 'upset']
        
        surprise_keywords_ja = ['é©š', 'ã³ã£ãã‚Š', 'ã™ã”ã„', 'ã¾ã•ã‹', 'ãˆã£']
        surprise_keywords_en = ['surprise', 'wow', 'amazing', 'unexpected', 'really']
        
        # æ—¥æœ¬èªã¨è‹±èªä¸¡æ–¹ã‚’ãƒã‚§ãƒƒã‚¯
        if any(keyword in text_lower for keyword in positive_keywords_ja + positive_keywords_en):
            return 'happy'
        elif any(keyword in text_lower for keyword in negative_keywords_ja + negative_keywords_en):
            return 'sad'
        elif any(keyword in text_lower for keyword in angry_keywords_ja + angry_keywords_en):
            return 'angry'
        elif any(keyword in text_lower for keyword in surprise_keywords_ja + surprise_keywords_en):
            return 'surprised'
        else:
            return 'neutral'
    
    def _ensure_complete_sentence(self, text):
        """æ–‡ãŒå®Œå…¨ã«çµ‚ã‚ã£ã¦ã„ã‚‹ã‹ç¢ºèªã—ã€å¿…è¦ãªã‚‰ä¿®æ­£"""
        text = text.strip()
        
        # æ–‡æœ«ã®å¥èª­ç‚¹ã‚’ãƒã‚§ãƒƒã‚¯
        if not text:
            return text
        
        # å¥èª­ç‚¹ã§çµ‚ã‚ã£ã¦ã„ãªã„å ´åˆ
        if not text.endswith(('ã€‚', 'ï¼', 'ï¼Ÿ', 'ã€', '...', 'ï½', 'ãƒ¼', 'ã­', 'ã‚ˆ', 'ã§ã™', 'ã¾ã™', '.', '!', '?', '"', "'")):
            # æœ€å¾Œã®æ–‡ã‚’è¦‹ã¤ã‘ã‚‹
            sentences = re.split(r'[ã€‚ï¼ï¼Ÿ.!?]', text)
            if len(sentences) > 1:
                # æœ€å¾Œã®ä¸å®Œå…¨ãªæ–‡ã‚’å‰Šé™¤
                complete_sentences = sentences[:-1]
                # å¥èª­ç‚¹ã‚’å¾©å…ƒ
                result = ""
                for i, sent in enumerate(complete_sentences):
                    if sent.strip():
                        # å…ƒã®å¥èª­ç‚¹ã‚’è¦‹ã¤ã‘ã‚‹
                        match = re.search(f'{re.escape(sent)}([ã€‚ï¼ï¼Ÿ.!?])', text)
                        if match:
                            result += sent + match.group(1)
                        else:
                            result += sent + ("." if any(c in 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ' for c in sent) else "ã€‚")
                return result.strip()
            else:
                # 1æ–‡ã ã‘ã®å ´åˆã¯é©åˆ‡ãªçµ‚ã‚ã‚Šæ–¹ã‚’è¿½åŠ 
                # è‹±èªã®å ´åˆ
                if any(c in 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ' for c in text):
                    # ç–‘å•æ–‡ã‹ã©ã†ã‹åˆ¤å®š
                    question_words = ['what', 'where', 'when', 'why', 'how', 'who', 'which', 'is', 'are', 'do', 'does', 'can', 'could', 'would', 'should']
                    if any(text.lower().startswith(word) for word in question_words):
                        return text + "?"
                    else:
                        return text + "."
                # æ—¥æœ¬èªã®å ´åˆ
                elif text.endswith(('ã ', 'ã‚‹', 'ãŸ', 'ã§ã™', 'ã¾ã™')):
                    return text + "ã­ã€‚"
                else:
                    return text + "ã€‚"
        
        return text
    
    def _trim_to_complete_sentence(self, text, max_length):
        """æŒ‡å®šã•ã‚ŒãŸé•·ã•ä»¥å†…ã§å®Œå…¨ãªæ–‡ã«åˆ‡ã‚Šè©°ã‚ã‚‹"""
        if len(text) <= max_length:
            return text
        
        # æ–‡ã®åŒºåˆ‡ã‚Šã§åˆ†å‰²
        sentences = re.split(r'([ã€‚ï¼ï¼Ÿ.!?])', text)
        
        result = ""
        for i in range(0, len(sentences), 2):
            if i+1 < len(sentences):
                # æ–‡ã¨å¥èª­ç‚¹ã‚’ã‚»ãƒƒãƒˆã§è¿½åŠ 
                next_part = sentences[i] + sentences[i+1]
                if len(result + next_part) <= max_length:
                    result += next_part
                else:
                    break
            else:
                # æœ€å¾Œã®æ–‡ï¼ˆå¥èª­ç‚¹ãªã—ï¼‰
                if len(result + sentences[i]) <= max_length:
                    result += sentences[i]
                break
        
        return self._ensure_complete_sentence(result)
    
    # ä»–ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯æ—¢å­˜ã®ã¾ã¾ï¼ˆçœç•¥ï¼‰
    def get_relationship_prompt(self, relationship_style):
        """ğŸ¯ é–¢ä¿‚æ€§ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ"""
        prompts = {
            'formal': """
ã€è©±ã—æ–¹ã€‘
- åˆå¯¾é¢ã®ç›¸æ‰‹ã¨ã—ã¦ã€ä¸å¯§ã§ç¤¼å„€æ­£ã—ãè©±ã™
- æ•¬èªã‚’ä½¿ã„ã€æ¸©ã‹ã¿ã®ã‚ã‚‹æ¨™æº–èªã§æ¥ã™ã‚‹
- ã€Œã§ã™ã€ã€Œã¾ã™ã€èª¿ã‚’åŸºæœ¬ã¨ã™ã‚‹
- ä¾‹ï¼šã€Œãã†ã§ã™ã­ã€ã€Œã€œã—ã¦ãã ã•ã„ã­ã€ã€Œã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€
            """,
            'slightly_casual': """
ã€è©±ã—æ–¹ã€‘
- å°‘ã—è¦ªã—ããªã£ãŸç›¸æ‰‹ã¨ã—ã¦ã€ã¾ã ä¸å¯§ã ã‘ã©è¦ªã—ã¿ã‚’è¾¼ã‚ã¦
- æ•¬èªã¯æ®‹ã—ã¤ã¤ã€æ™‚ã€…ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ãªè¡¨ç¾ãŒæ··ã˜ã‚‹
- ã€Œã¾ãŸæ¥ã¦ãã ã•ã£ãŸã‚“ã§ã™ã­ã€ã®ã‚ˆã†ãªè¦ªã—ã¿ã‚„ã™ã„è¡¨ç¾
- ä¾‹ï¼šã€Œå¬‰ã—ã„ã§ã™ã€œã€ã€Œã€œã—ã¦ã¿ã¦ã‚‚ã„ã„ã§ã™ã‚ˆã€
            """,
            'casual': """
ã€è©±ã—æ–¹ã€‘
- é¡”è¦‹çŸ¥ã‚Šã¨ã—ã¦ã€è¦ªã—ã¿ã‚„ã™ã„å£èª¿ã§
- æ•¬èªã¨ã‚¿ãƒ¡å£ãŒåŠã€…ãã‚‰ã„
- ãƒªãƒ©ãƒƒã‚¯ã‚¹ã—ãŸé›°å›²æ°—ã‚’å‡ºã™
- ä¾‹ï¼šã€Œæœ€è¿‘ã©ã†ã—ã¦ã‚‹ï¼Ÿã€ã€Œã€œã‚„ã£ã¦ã¿ãŸã‚‰ï¼Ÿã€ã€Œã„ã„ã­ï¼ã€
            """,
            'friendly': """
ã€è©±ã—æ–¹ã€‘
- å¸¸é€£ã•ã‚“ã¨ã—ã¦ã€ã‚¿ãƒ¡å£ä¸­å¿ƒã®è¦ªã—ã„æ„Ÿã˜
- å†—è«‡ã‚‚äº¤ãˆã‚‹
- ã€Œã„ã¤ã‚‚ã‚ã‚ŠãŒã¨ã†ï¼ã€ã®ã‚ˆã†ãªè¦ªå¯†ãªè¡¨ç¾
- ä¾‹ï¼šã€Œä»Šæ—¥ã‚‚æ¥ãŸã‚“ã ã€œã€ã€Œã™ã”ãã„ã„ã­ã€ã€Œæœ¬å½“ã ã‚ˆã€œã€
            """,
            'friend': """
ã€è©±ã—æ–¹ã€‘
- å‹é”ã¨ã—ã¦ã€å®Œå…¨ã«ã‚¿ãƒ¡å£ã§
- å†—è«‡ã‚„è»½å£ã‚‚è‡ªç„¶ã«
- ç›¸æ‰‹ã®å‘¼ã³æ–¹ã‚‚è¦ªã—ã¿ã‚„ã™ã
- ä¾‹ï¼šã€ŒãŠãƒ¼ï¼æ¥ãŸã­ï¼ã€ã€Œãªã‚“ã§ã‚ˆï¼ˆç¬‘ï¼‰ã€ã€Œä¸€ç·’ã«ã€œã—ã‚ˆã†ã€
            """,
            'bestfriend': """
ã€è©±ã—æ–¹ã€‘
- è¦ªå‹ã¨ã—ã¦ã€ä½•ã§ã‚‚è©±ã›ã‚‹é–¢ä¿‚
- æ˜”ã‹ã‚‰ã®å‹é”ã®ã‚ˆã†ãªå£èª¿
- ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãªè©±é¡Œã‚‚OK
- ä¾‹ï¼šã€Œæ¥ãŸæ¥ãŸã€œï¼ã€ã€Œã¶ã£ã¡ã‚ƒã‘ã€œã€ã€Œã™ã”ãåˆ†ã‹ã‚‹ï¼ã€
            """
        }
        
        return prompts.get(relationship_style, prompts['formal'])
    
    def generate_relationship_based_suggestions(self, relationship_style, current_topic, selected_suggestions=[]):
        """ğŸ¯ é–¢ä¿‚æ€§ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸã‚µã‚¸ã‚§ã‚¹ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆï¼ˆé‡è¤‡æ’é™¤æ©Ÿèƒ½ä»˜ãï¼‰"""
        
        # ã‚µã‚¸ã‚§ã‚¹ã‚·ãƒ§ãƒ³ã®éšå±¤æ§‹é€ ã‚’å®šç¾©
        suggestion_hierarchy = {
            'overview': {  # æ¦‚è¦ãƒ¬ãƒ™ãƒ«
                'priority': 1,
                'suggestions': [
                    "äº¬å‹ç¦…ã£ã¦ã©ã‚“ãªæŠ€è¡“ï¼Ÿ",
                    "å‹ç¦…æŸ“ã®æ­´å²ã«ã¤ã„ã¦æ•™ãˆã¦",
                    "ä»–ã®æŸ“è‰²æŠ€æ³•ã¨ã®é•ã„ã¯ï¼Ÿ",
                    "äº¬éƒ½ã®ä¼çµ±å·¥èŠ¸ã«ã¤ã„ã¦"
                ]
            },
            'technical': {  # æŠ€è¡“è©³ç´°ãƒ¬ãƒ™ãƒ«
                'priority': 2,
                'suggestions': [
                    "ã®ã‚ŠãŠãå·¥ç¨‹ã£ã¦ä½•ï¼Ÿ",
                    "åˆ¶ä½œã®10å·¥ç¨‹ã‚’è©³ã—ã",
                    "ä½¿ç”¨ã™ã‚‹é“å…·ã«ã¤ã„ã¦",
                    "ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æŠ€æ³•ã®ç§˜å¯†",
                    "ç³¸ç›®ç³Šã®ç‰¹å¾´ã¯ï¼Ÿ"
                ]
            },
            'personal': {  # è·äººå€‹äººãƒ¬ãƒ™ãƒ«
                'priority': 3,
                'suggestions': [
                    "è·äººã«ãªã£ãŸãã£ã‹ã‘ã¯ï¼Ÿ",
                    "15å¹´é–“ã§ä¸€ç•ªå¤§å¤‰ã ã£ãŸã“ã¨",
                    "ä»•äº‹ã®ã‚„ã‚ŠãŒã„ã¯ï¼Ÿ",
                    "ä¸€æ—¥ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ï¼Ÿ",
                    "å°†æ¥ã®å¤¢ã‚„ç›®æ¨™ã¯ï¼Ÿ"
                ]
            }
        }
        
        # é–¢ä¿‚æ€§ãƒ¬ãƒ™ãƒ«åˆ¥ã®è¿½åŠ ã‚µã‚¸ã‚§ã‚¹ã‚·ãƒ§ãƒ³
        relationship_specific = {
            'formal': {
                'default': ["ä½“é¨“æ•™å®¤ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ", "ä½œå“ã‚’è¦‹å­¦ã§ãã¾ã™ã‹ï¼Ÿ", "äº¬å‹ç¦…ã®ä¾¡æ ¼å¸¯ã¯ï¼Ÿ"],
            },
            'slightly_casual': {
                'default': ["æœ€è¿‘ã®ä½œå“ã«ã¤ã„ã¦", "è‹¥ã„äººã«ã‚‚äººæ°—ï¼Ÿ", "ä»•äº‹ã§å¬‰ã—ã‹ã£ãŸã“ã¨"],
            },
            'casual': {
                'default': ["é¢ç™½ã„ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚ã‚‹ï¼Ÿ", "å¤±æ•—è«‡ã¨ã‹èããŸã„", "ä¼‘æ—¥ã¯ä½•ã—ã¦ã‚‹ï¼Ÿ"],
            },
            'friendly': {
                'default': ["æœ€è¿‘ã©ã†ï¼Ÿ", "ã¶ã£ã¡ã‚ƒã‘è©±ã‚ã‚‹ï¼Ÿ", "æ¥­ç•Œã®è£è©±ã¨ã‹"],
            },
            'friend': {
                'default': ["å…ƒæ°—ã«ã—ã¦ãŸï¼Ÿ", "æ‚©ã¿ã¨ã‹ã‚ã‚‹ï¼Ÿ", "å°†æ¥ã©ã†ã™ã‚‹ï¼Ÿ"],
            },
            'bestfriend': {
                'default': ["ä¹…ã—ã¶ã‚Šã€œå…ƒæ°—ï¼Ÿ", "ç§˜å¯†ã®è©±ã‚ã‚‹ï¼Ÿ", "äººç”Ÿã«ã¤ã„ã¦èªã‚ã†"],
            }
        }
        
        # åˆå›è¨ªå•ã‹ã©ã†ã‹ã‚’åˆ¤å®šï¼ˆé¸æŠå±¥æ­´ãŒ3å€‹ä»¥ä¸‹ï¼‰
        is_new_visitor = len(selected_suggestions) <= 3
        
        suggestions = []
        
        if is_new_visitor:
            # åˆå›ã¯éšå±¤é †ã«ã‚µã‚¸ã‚§ã‚¹ã‚·ãƒ§ãƒ³ã‚’é¸æŠ
            for category in ['overview', 'technical', 'personal']:
                category_suggestions = suggestion_hierarchy[category]['suggestions']
                # æœªé¸æŠã®ã‚‚ã®ã‹ã‚‰é¸ã¶
                available = [s for s in category_suggestions if s not in selected_suggestions]
                if available:
                    suggestions.append(random.choice(available))
                    if len(suggestions) >= 3:
                        break
        else:
            # ãƒªãƒ”ãƒ¼ã‚¿ãƒ¼ã«ã¯é–¢ä¿‚æ€§ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸã‚µã‚¸ã‚§ã‚¹ã‚·ãƒ§ãƒ³
            specific_suggestions = relationship_specific.get(relationship_style, relationship_specific['formal'])
            available_specific = [s for s in specific_suggestions['default'] if s not in selected_suggestions]
            
            # é–¢ä¿‚æ€§åˆ¥ã®ã‚µã‚¸ã‚§ã‚¹ã‚·ãƒ§ãƒ³ã‹ã‚‰1ã¤
            if available_specific:
                suggestions.append(random.choice(available_specific))
            
            # æ®‹ã‚Šã¯å…¨ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰é¸æŠ
            all_suggestions = []
            for category in suggestion_hierarchy.values():
                all_suggestions.extend(category['suggestions'])
            
            available_all = [s for s in all_suggestions if s not in selected_suggestions and s not in suggestions]
            if available_all:
                remaining_count = min(2, len(available_all))
                suggestions.extend(random.sample(available_all, remaining_count))
        
        # 3ã¤ã«æº€ãŸãªã„å ´åˆã¯ã€å…¨ä½“ã‹ã‚‰è£œå……
        if len(suggestions) < 3:
            all_possible = []
            for category in suggestion_hierarchy.values():
                all_possible.extend(category['suggestions'])
            for specific in relationship_specific.values():
                all_possible.extend(specific['default'])
            
            available_all = [s for s in all_possible if s not in selected_suggestions and s not in suggestions]
            if available_all:
                needed = 3 - len(suggestions)
                suggestions.extend(random.sample(available_all, min(needed, len(available_all))))
        
        # é¸æŠã•ã‚ŒãŸã‚µã‚¸ã‚§ã‚¹ã‚·ãƒ§ãƒ³ã‚’è¨˜éŒ²
        self.selected_suggestions.extend(suggestions)
        
        return suggestions[:3]  # æœ€å¤§3ã¤ã¾ã§
    
    def extract_topic(self, question, answer):
        """è³ªå•ã¨å›ç­”ã‹ã‚‰ä¸»è¦ãªãƒˆãƒ”ãƒƒã‚¯ã‚’æŠ½å‡º"""
        # ã‚·ãƒ³ãƒ—ãƒ«ãªå®Ÿè£…ï¼šåè©å¥ã‚’æŠ½å‡º
        topics = []
        
        # äº¬å‹ç¦…é–¢é€£ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        keywords = ['äº¬å‹ç¦…', 'ã®ã‚ŠãŠã', 'ç³¸ç›®ç³Š', 'æŸ“è‰²', 'å‹ç¦…æŸ“', 'è·äºº', 'ä¼çµ±å·¥èŠ¸', 'åˆ¶ä½œéç¨‹', 'å·¥ç¨‹', 'æŠ€æ³•', 'ç€ç‰©', 'æ¨¡æ§˜', 'æŸ„']
        
        # è³ªå•ã¨å›ç­”ã®ä¸¡æ–¹ã‹ã‚‰æ¤œç´¢
        combined_text = question + " " + answer
        
        for keyword in keywords:
            if keyword in combined_text:
                topics.append(keyword)
        
        # æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„ãƒˆãƒ”ãƒƒã‚¯ã‚’è¿”ã™
        return topics[0] if topics else "äº¬å‹ç¦…ã®æŠ€è¡“"
    
    def generate_next_suggestions(self, question, answer, relationship_style='formal', selected_suggestions=[], language='ja'):
        """æ¬¡ã®ã‚µã‚¸ã‚§ã‚¹ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆï¼ˆé–¢ä¿‚æ€§ãƒ¬ãƒ™ãƒ«ãƒ»å¤šè¨€èªå¯¾å¿œç‰ˆï¼‰"""
        
        # ğŸ¯ æ–°è¦è¿½åŠ ï¼šæ®µéšåˆ¥ã‚µã‚¸ã‚§ã‚¹ãƒãƒ§ãƒ³æ©Ÿèƒ½ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ï¼ˆAWSç’°å¢ƒå¯¾å¿œï¼‰
        global _static_qa_module
        if _static_qa_module is None:
            _static_qa_module = _import_static_qa_functions()
        
        # å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ãŸé–¢æ•°ã‚’ä½¿ç”¨ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–ï¼‰
        staged_suggestions = None
        if _static_qa_module:
            try:
                # selected_suggestionsãŒæ­£ã—ã„ãƒªã‚¹ãƒˆå½¢å¼ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
                if isinstance(selected_suggestions, list):
                    suggestions_count = len(selected_suggestions)
                else:
                    suggestions_count = 0
                    print(f"[WARNING] selected_suggestions is not a list: {type(selected_suggestions)}")
                
                current_stage = _static_qa_module.get_current_stage(suggestions_count)
                staged_suggestions = _static_qa_module.get_staged_suggestions_multilang(current_stage, language, selected_suggestions)
                
                # æˆ»ã‚Šå€¤ãŒæ­£ã—ã„ãƒªã‚¹ãƒˆå½¢å¼ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
                if not isinstance(staged_suggestions, list):
                    print(f"[WARNING] staged_suggestions is not a list: {type(staged_suggestions)}")
                    staged_suggestions = None
                
            except Exception as e:
                print(f"æ®µéšåˆ¥ã‚µã‚¸ã‚§ã‚¹ãƒãƒ§ãƒ³å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                print(f"Error type: {type(e).__name__}")
                import traceback
                traceback.print_exc()
                staged_suggestions = None
        else:
            print("[WARNING] _static_qa_module is None - using fallback suggestions")
        
        # æ®µéšåˆ¥ã‚µã‚¸ã‚§ã‚¹ãƒãƒ§ãƒ³ãŒå–å¾—ã§ããŸå ´åˆã¯ãã‚Œã‚’è¿”ã™
        if staged_suggestions:
            return staged_suggestions
        
        # ğŸ¯ ä¿®æ­£ï¼šè‹±èªã®å ´åˆã®ç°¡æ˜“ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚’è¿½åŠ 
        if language == 'en':
            # è‹±èªç”¨ã®ç°¡æ˜“ã‚µã‚¸ã‚§ã‚¹ãƒãƒ§ãƒ³
            fallback_suggestions = [
                "Tell me more about Kyo-Yuzen",
                "What's the most interesting part of your work?",
                "Any advice for beginners?",
                "What makes Kyo-Yuzen special?",
                "How did you learn this craft?",
                "What's your favorite part of the process?"
            ]
            
            # é‡è¤‡ã‚’æ’é™¤
            available = [s for s in fallback_suggestions if s not in selected_suggestions]
            
            # 3å€‹ã¾ã§è¿”ã™
            import random
            if len(available) <= 3:
                return available
            else:
                return random.sample(available, 3)
        
        # æ—¢å­˜ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦ç¶™ç¶šï¼ˆæ—¥æœ¬èªã®å ´åˆã®ã¿ï¼‰
        # ç¾åœ¨ã®ãƒˆãƒ”ãƒƒã‚¯ã‚’æŠ½å‡º
        current_topic = self.extract_topic(question, answer)
        
        # ğŸ¯ é–¢ä¿‚æ€§ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸã‚µã‚¸ã‚§ã‚¹ãƒãƒ§ãƒ³ã‚’ç”Ÿæˆï¼ˆé‡è¤‡æ’é™¤æ©Ÿèƒ½ä»˜ãï¼‰
        return self.generate_relationship_based_suggestions(relationship_style, current_topic, selected_suggestions)
    
    def answer_with_suggestions(
        self,
        question: str,
        context: str = "",
        question_count: int = 1,
        relationship_style: str = 'formal',
        previous_emotion: str = 'neutral',
        selected_suggestions: List[str] = [],
        language: str = 'ja',  # ğŸ¯ æ–°è¦è¿½åŠ ï¼šè¨€èªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        explained_terms: Dict = {}  # ğŸ¯ æ–°è¦è¿½åŠ ï¼šèª¬æ˜æ¸ˆã¿ç”¨èªè¾æ›¸
    ) -> Dict:
        """è³ªå•ã«å›ç­”ã—ã€ã‚µã‚¸ã‚§ã‚¹ãƒãƒ§ãƒ³ã‚’ç”Ÿæˆï¼ˆç”¨èªç®¡ç†ãƒ»å¤šè¨€èªå¯¾å¿œç‰ˆï¼‰"""
        try:
            # å›ç­”ã‚’ç”Ÿæˆï¼ˆğŸ¯ æ–°è¦è¿½åŠ ï¼šlanguageå¼•æ•°ã‚’æ¸¡ã™ï¼‰
            answer = self.answer_question(
                question,
                context,
                question_count,
                relationship_style,
                previous_emotion,
                language  # ğŸ¯ æ–°è¦è¿½åŠ 
            )
            
            # ğŸ¯ æ–°è¦è¿½åŠ ï¼šç”¨èªç®¡ç†æ©Ÿèƒ½ã‚’é©ç”¨ï¼ˆæ—¥æœ¬èªã®å ´åˆã®ã¿ï¼‰
            if language == 'ja':
                answer, updated_explained_terms = self.manage_explained_terms(answer, explained_terms)
            else:
                updated_explained_terms = explained_terms
            
            # ãƒˆãƒ”ãƒƒã‚¯ã‚’æŠ½å‡º
            topic = self.extract_topic(question, answer)
            
            # æ¬¡ã®ã‚µã‚¸ã‚§ã‚¹ãƒãƒ§ãƒ³ã‚’ç”Ÿæˆï¼ˆğŸ¯ æ–°è¦è¿½åŠ ï¼šlanguageå¼•æ•°ã‚’æ¸¡ã™ï¼‰
            next_suggestions = self.generate_next_suggestions(
                question,
                answer,
                relationship_style,
                selected_suggestions,
                language  # ğŸ¯ æ–°è¦è¿½åŠ 
            )
            
            # æ„Ÿæƒ…ã‚’åˆ†æ
            user_emotion = self._analyze_user_emotion(question)
            
            # ç¾åœ¨ã®æ™‚é–“å¸¯ã‚’å–å¾—
            hour = datetime.now().hour
            time_of_day = (
                'morning' if 5 <= hour < 12
                else 'afternoon' if 12 <= hour < 17
                else 'evening' if 17 <= hour < 22
                else 'night'
            )
            
            # ç²¾ç¥çŠ¶æ…‹ã‚’æ›´æ–°
            self._update_mental_state(user_emotion, topic, time_of_day)
            
            # æ¬¡ã®æ„Ÿæƒ…ã‚’è¨ˆç®—
            next_emotion = self._calculate_next_emotion(
                previous_emotion,
                user_emotion,
                self.mental_states
            )
            
            return {
                'answer': answer,
                'suggestions': next_suggestions,
                'current_emotion': next_emotion,
                'mental_state': self.mental_states,
                'explained_terms': updated_explained_terms  # ğŸ¯ æ–°è¦è¿½åŠ ï¼šæ›´æ–°ã•ã‚ŒãŸèª¬æ˜æ¸ˆã¿ç”¨èª
            }
            
        except Exception as e:
            print(f"å›ç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            # ğŸ¯ ä¿®æ­£ï¼šè¨€èªã«å¿œã˜ãŸã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            if language == 'en':
                return {
                    'answer': "Sorry, an error occurred while generating the response.",
                    'suggestions': [],
                    'current_emotion': 'neutral',
                    'mental_state': self.mental_states,
                    'explained_terms': explained_terms
                }
            else:
                return {
                    'answer': "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚å›ç­”ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚",
                    'suggestions': [],
                    'current_emotion': 'neutral',
                    'mental_state': self.mental_states,
                    'explained_terms': explained_terms
                }
    
    def get_knowledge_context(self, query):
        """è³ªå•ã«é–¢é€£ã™ã‚‹å°‚é–€çŸ¥è­˜ã‚’å–å¾—"""
        if not self.knowledge_base:
            return ""
        
        relevant_knowledge = []
        query_lower = query.lower()
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°ã§é–¢é€£çŸ¥è­˜ã‚’æŠ½å‡º
        keywords = ['äº¬å‹ç¦…', 'ã®ã‚ŠãŠã', 'ç³¸ç›®ç³Š', 'æŸ“è‰²', 'è·äºº', 'ä¼çµ±', 'å·¥èŠ¸', 'ç€ç‰©', 'åˆ¶ä½œ', 'å·¥ç¨‹', 'æ¨¡æ§˜', 'ãƒ‡ã‚¶ã‚¤ãƒ³', 'æŠ€è¡“']
        
        for category, subcategories in self.knowledge_base.items():
            category_matched = False
            
            # ã‚«ãƒ†ã‚´ãƒªåã¾ãŸã¯ã‚¯ã‚¨ãƒªã§ãƒãƒƒãƒãƒ³ã‚°
            if any(keyword in query_lower for keyword in keywords) or any(keyword in category.lower() for keyword in keywords):
                category_matched = True
            
            if category_matched or query_lower in category.lower():
                relevant_knowledge.append(f"\nã€{category}ã€‘")
                for subcategory, items in subcategories.items():
                    if subcategory != '_general':
                        relevant_knowledge.append(f"{subcategory}:")
                    for item in items:
                        relevant_knowledge.append(f"- {item}")
        
        return "\n".join(relevant_knowledge) if relevant_knowledge else ""
    
    def test_system(self):
        """ã‚·ã‚¹ãƒ†ãƒ ã®å‹•ä½œç¢ºèªï¼ˆé–¢ä¿‚æ€§ãƒ¬ãƒ™ãƒ«ãƒ»æ„Ÿæƒ…é€£ç¶šæ€§å¯¾å¿œç‰ˆï¼‰"""
        print("\n=== ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
        
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šã®ç¢ºèª
        print("\nã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šã€‘")
        char_prompt = self.get_character_prompt()
        print(char_prompt[:300] + "..." if len(char_prompt) > 300 else char_prompt)
        
        # å°‚é–€çŸ¥è­˜ã®ç¢ºèª
        print("\nã€å°‚é–€çŸ¥è­˜ã‚µãƒ³ãƒ—ãƒ«ã€‘")
        sample_knowledge = self.get_knowledge_context("äº¬å‹ç¦…")
        print(sample_knowledge[:300] + "..." if len(sample_knowledge) > 300 else sample_knowledge)
        
        # å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç¢ºèª
        print("\nã€å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚µãƒ³ãƒ—ãƒ«ã€‘")
        patterns = self.get_response_pattern()
        print(patterns[:300] + "..." if len(patterns) > 300 else patterns)
        
        # ã‚µã‚¸ã‚§ã‚¹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ç¢ºèª
        print("\nã€ã‚µã‚¸ã‚§ã‚¹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã€‘")
        if hasattr(self, 'suggestion_templates') and self.suggestion_templates:
            for category, templates in self.suggestion_templates.items():
                print(f"{category}:")
                for template in templates[:3]:  # æœ€åˆã®3ã¤ã ã‘è¡¨ç¤º
                    print(f"  - {template}")
        else:
            print("ã‚µã‚¸ã‚§ã‚¹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # ãƒ†ã‚¹ãƒˆè³ªå•ï¼ˆé–¢ä¿‚æ€§ãƒ¬ãƒ™ãƒ«ãƒ»æ„Ÿæƒ…é€£ç¶šæ€§ï¼‰
        print("\nã€ãƒ†ã‚¹ãƒˆå›ç­”ï¼ˆé–¢ä¿‚æ€§ãƒ¬ãƒ™ãƒ«ãƒ»æ„Ÿæƒ…é€£ç¶šæ€§ï¼‰ã€‘")
        test_questions = [
            ("äº¬å‹ç¦…ã«ã¤ã„ã¦æ•™ãˆã¦", "", 1, 'formal', 'neutral'),
            ("ã™ã”ã„ã­ï¼ã‚‚ã£ã¨è©³ã—ãèããŸã„", "", 1, 'formal', 'happy'),
            ("æœ€è¿‘ã©ã†ï¼Ÿ", "", 1, 'bestfriend', 'neutral'),
            ("ã¡ã‚‡ã£ã¨ç–²ã‚ŒãŸ...", "ã€æœ€è¿‘ã®ä¼šè©±ã€‘\nãƒ¦ãƒ¼ã‚¶ãƒ¼: ä»•äº‹å¤§å¤‰ï¼Ÿ\nã‚ãªãŸ: ãã†ã§ã™ã­ã€æœã‹ã‚‰æ™©ã¾ã§æŸ“ã‚ã¦ã„ã‚‹ã¨ã•ã™ãŒã«ç–²ã‚Œã¾ã™", 1, 'friend', 'sad'),
        ]
        
        for q, context, count, style, emotion in test_questions:
            print(f"\nè³ªå•: {q}")
            print(f"é–¢ä¿‚æ€§ãƒ¬ãƒ™ãƒ«: {style}")
            print(f"å‰å›ã®æ„Ÿæƒ…: {emotion}")
            if context:
                print(f"æ–‡è„ˆ: {context}")
            print(f"è³ªå•å›æ•°: {count}å›ç›®")
            response_data = self.answer_with_suggestions(q, context, count, style, emotion)
            print(f"å›ç­”: {response_data['answer']}")
            print(f"ã‚µã‚¸ã‚§ã‚¹ã‚·ãƒ§ãƒ³: {response_data['suggestions']}")
            print(f"ç¾åœ¨ã®æ„Ÿæƒ…: {response_data.get('current_emotion', 'unknown')}")
        
        print("\n=== ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆå®Œäº† ===")
    
    async def process_documents(self, directory="uploads"):
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‡¦ç†ã—ã¦ãƒ™ã‚¯ãƒˆãƒ«DBã«ä¿å­˜"""
        try:
            # Supabaseã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
            files = self.supabase.storage.from_('uploads').list()
            
            # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
            temp_dir = "temp_uploads"
            os.makedirs(temp_dir, exist_ok=True)
            
            documents = []
            
            for file in files:
                try:
                    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                    file_data = self.supabase.storage.from_('uploads').download(file['name'])
                    temp_path = os.path.join(temp_dir, file['name'])
                    
                    with open(temp_path, 'wb') as f:
                        f.write(file_data)
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¨®é¡ã«å¿œã˜ã¦ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’é¸æŠ
                    if file['name'].endswith('.pdf'):
                        loader = PyPDFLoader(temp_path)
                    else:
                        loader = TextLoader(temp_path)
                    
                    documents.extend(loader.load())
                    
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                    os.remove(temp_path)
                    
                except Exception as e:
                    print(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼ ({file['name']}): {e}")
                    continue
            
            # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤
            os.rmdir(temp_dir)
            
            if not documents:
                print("å‡¦ç†å¯èƒ½ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                return False
            
            # ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²
            text_splitter = CharacterTextSplitter(
                chunk_size=1000,
                chunk_overlap=200,
                separator="\n"
            )
            
            split_docs = text_splitter.split_documents(documents)
            
            # ãƒ™ã‚¯ãƒˆãƒ«DBã‚’ä½œæˆã¾ãŸã¯æ›´æ–°
            if self.db is None:
                self.db = Chroma.from_documents(
                    documents=split_docs,
                    embedding=self.embeddings,
                    persist_directory=self.persist_directory
                )
            else:
                self.db.add_documents(split_docs)
            
            # æ°¸ç¶šåŒ–
            self.db.persist()
            
            # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’æ›´æ–°
            self._load_all_knowledge()
            
            print(f"âœ… {len(split_docs)}å€‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‡¦ç†ã—ã¾ã—ãŸ")
            return True
            
        except Exception as e:
            print(f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            return False